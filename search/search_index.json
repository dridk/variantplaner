{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VariantPlaner","text":"<p>A tool kit to manage many variant without many cpu and ram ressource.</p>"},{"location":"#installation","title":"Installation","text":"<p>With <code>pip</code>: <pre><code>pip install git+https://github.com/natir/variantplaner.git@0.1.0-alpha#egg=variantplaner\n</code></pre></p> <p>With <code>pipx</code>: <pre><code>python -m pip install --user pipx\npipx install git+https://github.com/natir/variantplaner.git@0.1.0-alpha#egg=variantplaner\n</code></pre></p>"},{"location":"#usage","title":"Usage","text":"<p>This section present basic usage for a more complete exemple check our usage page</p> <p>WARNING: variantplaner support only not compressed file, sorry it's a downstream trouble.</p>"},{"location":"#convert-vcf-in-parquet","title":"Convert vcf in parquet","text":"<pre><code>variantplaner vcf2parquet -i input.vcf -v variants.parquet -g genotypes.parquet -a annotations.parquet\n</code></pre> <p><code>-g</code> option isn't mandatory if you didn't set it you lose genotyping information. <code>-a</code> option isn't mandatory if you didn't set it you lose \"INFO\" fields information.</p> <p>Genotyping encoding:</p> <code>gt</code> parquet value translation 0 variants not present 1 heterozygote 2 homozygote 3 no information (only use in transmission file)"},{"location":"#convert-parquet-in-vcf","title":"Convert parquet in vcf","text":"<pre><code>variantplaner parquet2vcf -i variants.parquet -g genotypes.parquet -o output.vcf\n</code></pre> <p><code>-g</code> option isn't mandatory if you didn't set it information isn't add. This options have many options to control behavior of this subcommand, sorry for this complexity.</p>"},{"location":"#structuration-of-data","title":"Structuration of data","text":""},{"location":"#merge-variants","title":"Merge variants","text":"<p>Warning: this command could have huge memory and disk usage</p> <pre><code>variantplaner struct -i variants/1.parquet -i variants/2.parquet -i variants/3.parquet \u2026 -i variants/n.parquet variants -o variants.parquet\n</code></pre> <p>By default temporary file are write in /tmp you can use TMPDIR, TEMP or TMP to change this behavior.</p> <p>This command use divide and conquer algorithm to perform merge of variants option <code>-b|--bytes-memory-limit</code> control bytes size of chunk of files. Empirically ram usage is ten times bytes memory limit value.</p>"},{"location":"#partitioning-genotypes","title":"Partitioning genotypes","text":"<p>Warning: this command could have huge disk usage</p> <pre><code>variantplaner struct -i genotypes/1.parquet -i genotypes/2.parquet -i genotypes/3.parquet \u2026 -i genotypes/n.parquet genotypes -p partition_prefix/\n</code></pre>"},{"location":"#annotations","title":"Annotations","text":""},{"location":"#vcf-format","title":"Vcf format","text":"<pre><code>variantplaner annotations -i annotations.vcf -o annotations.parquet vcf -r annot_id --info CLNDN --info AF_ESP\n</code></pre> <p><code>clinvar.parquet</code> containts <code>id</code> of variant and info field select if you didn't set <code>info</code> option all info column are include.</p> <p>Option <code>-r|--rename-id</code> could be use to rename vcf id column name (default name is <code>vid</code>).</p>"},{"location":"#csv-format","title":"Csv format","text":"<pre><code>variantplaner annotations -i annotations.tsv -o annotations.parquet csv -c chr -p pos -r ref -a alt -s$'\\t' --info CLNDN --info AF_ESP\n</code></pre> <p>It's work same as vcf sub command but you must specify chromosome (<code>-c</code>), position (<code>-p</code>), reference (<code>-r</code>) and alternative (<code>-a</code>), you can change separate with option <code>-s</code></p>"},{"location":"#metadata","title":"Metadata","text":""},{"location":"#json-format","title":"Json format","text":"<pre><code>variantplaner metadata -i metadata.json -o metadata.parquet json -f sample -f link -f kindex\n</code></pre>"},{"location":"#csv-format_1","title":"Csv format","text":"<pre><code>variantplaner metadata -i metadata.csv -o metadata.parquet csv -c sample -c link -c kindex\n</code></pre>"},{"location":"#generate","title":"Generate","text":""},{"location":"#variants-transmission","title":"Variants transmission","text":"<p>It is sometimes useful to calculate the familial origin of variants.</p> <pre><code>variantplaner generate transmission -i genotypes.parquet -I index_sample_name -m mother_sample_name -f father_sample_name -t transmission.parquet\n</code></pre> <p><code>genotypes.parquet</code> file with variant of all family this file must contains <code>gt</code> and <code>samples</code> columns.</p> <p>In <code>transmission.parquet</code> each line contains an index sample variants, index, mother, father genotypes sample information and also column origin.</p> <p>Origin column contains a number with 3 digit: <pre><code>231\n\u2502\u2502\u2514 father genotype\n\u2502\u2514\u2500 mother genotype\n\u2514\u2500\u2500 index genotype\n</code></pre></p> <p>You can also use pedigree file: <pre><code>variantplaner generate transmission -i genotypes.parquet -p family.ped -t transmission.parquet\n</code></pre></p> <p>Warning: this command could have important RAM usage (propotionaly to number of sample index variants)</p>"},{"location":"#contribution","title":"Contribution","text":"<p>All contributions are welcome, see our \"How to contribute\" page.</p>"},{"location":"benchmark/","title":"Benchmark","text":""},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#010-2023-04-18","title":"0.1.0 - 2023-04-18","text":"<p>Compare with first commit</p>"},{"location":"changelog/#build","title":"Build","text":"<ul> <li>Bump minimal python version to 3.8 (f394c44 by Pierre Marijon).</li> </ul>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code_of_conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at pierre.marijon-ext@aphp.fr. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code_of_conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code_of_conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code_of_conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code_of_conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"code_of_conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p>"},{"location":"contributing/#environment-setup","title":"Environment setup","text":"<p>Nothing easier!</p> <p>Note</p> <p> Usage of pyenv is recommended</p> <p>After install pyenv run: <pre><code>pyenv install 3.9 3.10 3.11\n</code></pre></p> <p>Fork and clone the repository, then:</p> <pre><code>cd variantplaner\nmake setup\n</code></pre> <p>Note</p> <p> If it fails for some reason, you'll need to install PDM manually.</p> <p>You can install it with:</p> <pre><code>python3 -m pip install --user pipx\npipx install pdm\n</code></pre> <p>Now you can try running <code>make setup</code> again, or simply <code>pdm install</code>.</p> <p>You now have the dependencies installed.</p> <p>You can run the application with <code>pdm run variantplaner [ARGS...]</code>.</p> <p>Run <code>make help</code> to see all the available actions!</p>"},{"location":"contributing/#tasks","title":"Tasks","text":"<p>This project uses duty to run tasks. A Makefile is also provided. The Makefile will try to run certain tasks on multiple Python versions. If for some reason you don't want to run the task on multiple Python versions, you can do one of the following:</p> <ol> <li><code>export PYTHON_VERSIONS=</code>: this will run the task    with only the current Python version</li> <li>run the task directly with <code>pdm run duty TASK</code></li> </ol> <p>The Makefile detects if a virtual environment is activated, so <code>make</code> will work the same with the virtualenv activated or not.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>As usual:</p> <ol> <li>create a new branch: <code>git checkout -b feature-or-bugfix-name</code></li> <li>edit the code and/or the documentation</li> </ol> <p>Before committing:</p> <ol> <li>run <code>make format</code> to auto-format the code</li> <li>run <code>make check</code> to check everything (fix any warning)</li> <li>run <code>make test</code> to run the tests (fix any issue)</li> <li>if you updated the documentation or the project dependencies:<ol> <li>run <code>make docs</code></li> <li>go to http://localhost:8000 and check that everything looks good</li> </ol> </li> <li>follow our commit message convention</li> </ol> <p>If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review.</p> <p>Don't bother updating the changelog, we will take care of this.</p>"},{"location":"contributing/#commit-message-convention","title":"Commit message convention","text":"<p>Commit messages must follow our convention based on the Angular style or the Karma convention:</p> <pre><code>&lt;type&gt;[(scope)]: Subject\n\n[Body]\n</code></pre> <p>Subject and body must be valid Markdown. Subject must have proper casing (uppercase for first letter if it makes sense), but no dot at the end, and no punctuation in general.</p> <p>Scope and body are optional. Type can be:</p> <ul> <li><code>build</code>: About packaging, building wheels, etc.</li> <li><code>chore</code>: About packaging or repo/files management.</li> <li><code>ci</code>: About Continuous Integration.</li> <li><code>deps</code>: Dependencies update.</li> <li><code>docs</code>: About documentation.</li> <li><code>feat</code>: New feature.</li> <li><code>fix</code>: Bug fix.</li> <li><code>perf</code>: About performance.</li> <li><code>refactor</code>: Changes that are not features or bug fixes.</li> <li><code>style</code>: A change in code style/format.</li> <li><code>tests</code>: About tests.</li> </ul> <p>If you write a body, please add trailers at the end (for example issues and PR references, or co-authors), without relying on GitHub's flavored Markdown:</p> <pre><code>Body.\n\nIssue #10: https://github.com/namespace/project/issues/10\nRelated to PR namespace/other-project#15: https://github.com/namespace/other-project/pull/15\n</code></pre> <p>These \"trailers\" must appear at the end of the body, without any blank lines between them. The trailer title can contain any character except colons <code>:</code>. We expect a full URI for each trailer, not just GitHub autolinks (for example, full GitHub URLs for commits and issues, not the hash or the #issue-number).</p> <p>We do not enforce a line length on commit messages summary and body, but please avoid very long summaries, and very long lines in the body, unless they are part of code blocks that must not be wrapped.</p>"},{"location":"contributing/#pull-requests-guidelines","title":"Pull requests guidelines","text":"<p>Link to any related issue in the Pull Request message.</p> <p>During the review, we recommend using fixups:</p> <pre><code># SHA is the SHA of the commit you want to fix\ngit commit --fixup=SHA\n</code></pre> <p>Once all the changes are approved, you can squash your commits:</p> <pre><code>git rebase -i --autosquash main\n</code></pre> <p>And force-push:</p> <pre><code>git push -f\n</code></pre> <p>If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.</p>"},{"location":"credits/","title":"Credits","text":"<p><p>These projects were used to build <code>variantplaner</code>. Thank you!</p> <p><code>python</code> | <code>pdm</code> | <code>copier-pdm</code></p> </p>"},{"location":"credits/#exec-2--runtime-dependencies","title":"Runtime dependencies","text":"Project Summary Version (accepted) Version (last resolved) License <code>click</code> Composable command line interface toolkit <code>&gt;=8.1.3</code> <code>8.1.3</code> BSD-3-Clause <code>colorama</code> Cross-platform colored terminal text. <code>; platform_system == \"Windows\"</code> <code>0.4.6</code> BSD License <code>deltalake</code> Native Delta Lake Python binding based on delta-rs with Pandas integration <code>&gt;=0.8.0</code> <code>0.10.0</code> Apache-2.0 <code>fsspec</code> File-system specification <code>2023.6.0</code> BSD <code>numpy</code> Fundamental package for array computing in Python <code>&gt;=1.16.0</code> <code>1.24.3</code> BSD-3-Clause <code>pandas</code> Powerful data structures for data analysis, time series, and statistics <code>2.0.2</code> BSD License <code>polars</code> Blazingly fast DataFrame library <code>[pandas,numpy,pyarrow,fsspec,xlsx2csv,deltalake,timezone]&gt;=0.18</code> <code>0.18.2</code> MIT License <code>pyarrow</code> Python library for Apache Arrow <code>&gt;=7.0.0</code> <code>12.0.1</code> Apache License, Version 2.0 <code>python-dateutil</code> Extensions to the standard Python datetime module <code>&gt;=2.8.2</code> <code>2.8.2</code> Dual License <code>pytz</code> World timezone definitions, modern and historical <code>&gt;=2020.1</code> <code>2023.3</code> MIT <code>six</code> Python 2 and 3 compatibility utilities <code>&gt;=1.5</code> <code>1.16.0</code> MIT <code>typing-extensions</code> Backported and Experimental Type Hints for Python 3.7+ <code>&gt;=4.5.0</code> <code>4.6.3</code> Python Software Foundation License <code>tzdata</code> Provider of IANA time zone data <code>; platform_system == \"Windows\"</code> <code>2023.3</code> Apache-2.0 <code>xlsx2csv</code> xlsx to csv converter <code>&gt;=0.8.0</code> <code>0.8.1</code> MIT License"},{"location":"credits/#exec-2--development-dependencies","title":"Development dependencies","text":"Project Summary Version (accepted) Version (last resolved) License <code>altair</code> Vega-Altair: A declarative statistical visualization library for Python. <code>&gt;=5</code> <code>5.0.1</code> BSD License <code>ansimarkup</code> Produce colored terminal text with an xml-like markup <code>~=1.4</code> <code>1.5.0</code> Revised BSD License <code>attrs</code> Classes Without Boilerplate <code>&gt;=17.4.0</code> <code>23.1.0</code> MIT License <code>black</code> The uncompromising code formatter. <code>&gt;=23.1</code> <code>23.3.0</code> MIT <code>blacken-docs</code> Run Black on Python code blocks in documentation files. <code>&gt;=1.13</code> <code>1.14.0</code> ? <code>certifi</code> Python package for providing Mozilla's CA Bundle. <code>&gt;=2017.4.17</code> <code>2023.5.7</code> MPL-2.0 <code>charset-normalizer</code> The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. <code>&lt;4,&gt;=2</code> <code>3.1.0</code> MIT <code>click</code> Composable command line interface toolkit <code>&gt;=8.0.0</code> <code>8.1.3</code> BSD-3-Clause <code>colorama</code> Cross-platform colored terminal text. <code>; platform_system == \"Windows\"</code> <code>0.4.6</code> BSD License <code>coverage</code> Code coverage measurement for Python <code>[toml]&gt;=5.2.1</code> <code>7.2.7</code> Apache-2.0 <code>dparse</code> A parser for Python dependency files <code>&gt;=0.6.2</code> <code>0.6.2</code> ? <code>duty</code> A simple task runner. <code>&gt;=0.10</code> <code>0.11.1</code> ISC <code>exceptiongroup</code> Backport of PEP 654 (exception groups) <code>&gt;=1.0.0rc8; python_version &lt; \"3.11\"</code> <code>1.1.1</code> MIT License <code>execnet</code> execnet: rapid multi-Python deployment <code>&gt;=1.1</code> <code>1.9.0</code> MIT <code>failprint</code> Run a command, print its output only if it fails. <code>&gt;=0.11</code> <code>0.11.1</code> ISC <code>ghp-import</code> Copy your docs directly to the gh-pages branch. <code>&gt;=1.0</code> <code>2.1.0</code> Apache Software License <code>git-changelog</code> Automatic Changelog generator using Jinja2 templates. <code>&gt;=1.0</code> <code>1.0.1</code> ? <code>griffe</code> Signatures for entire Python programs. Extract the structure, the frame, the skeleton of your project, to generate API documentation or find breaking changes in your API. <code>&gt;=0.24</code> <code>0.29.0</code> ISC <code>idna</code> Internationalized Domain Names in Applications (IDNA) <code>&lt;4,&gt;=2.5</code> <code>3.4</code> BSD License <code>importlib-metadata</code> Read metadata from Python packages <code>&gt;=4.3; python_version &lt; \"3.10\"</code> <code>6.6.0</code> Apache Software License <code>iniconfig</code> brain-dead simple config-ini parsing <code>2.0.0</code> MIT License <code>jinja2</code> A very fast and expressive template engine. <code>3.1.2</code> BSD-3-Clause <code>jsonschema</code> An implementation of JSON Schema validation for Python <code>&gt;=3.0</code> <code>4.17.3</code> MIT <code>markdown</code> Python implementation of Markdown. <code>&lt;4.0.0,&gt;=3.3.3</code> <code>3.3.7</code> BSD License <code>markdown-callouts</code> Markdown extension: a classier syntax for admonitions <code>&gt;=0.2</code> <code>0.3.0</code> MIT <code>markdown-exec</code> Utilities to execute code blocks in Markdown files. <code>&gt;=0.5</code> <code>1.6.0</code> ISC <code>markupsafe</code> Safely add untrusted strings to HTML/XML markup. <code>&gt;=2.0</code> <code>2.1.3</code> BSD-3-Clause <code>mergedeep</code> A deep merge function for \ud83d\udc0d. <code>&gt;=1.3.4</code> <code>1.3.4</code> MIT License <code>mkdocs</code> Project documentation with Markdown. <code>&gt;=1.3</code> <code>1.4.3</code> BSD License <code>mkdocs-coverage</code> MkDocs plugin to integrate your coverage HTML report into your site. <code>&gt;=0.2</code> <code>0.2.7</code> ISC <code>mkdocs-gen-files</code> MkDocs plugin to programmatically generate documentation pages during the build <code>&gt;=0.3</code> <code>0.5.0</code> MIT License <code>mkdocs-literate-nav</code> MkDocs plugin to specify the navigation in Markdown instead of YAML <code>&gt;=0.4</code> <code>0.6.0</code> MIT License <code>mkdocs-material</code> Documentation that simply works <code>&gt;=7.3</code> <code>9.1.16</code> MIT License <code>mkdocs-material-extensions</code> Extension pack for Python Markdown and MkDocs Material. <code>&gt;=1.1</code> <code>1.1.1</code> MIT License <code>mkdocs-section-index</code> MkDocs plugin to allow clickable sections that lead to an index page <code>&gt;=0.3</code> <code>0.3.5</code> MIT License <code>mkdocstrings</code> Automatic documentation from sources, for MkDocs. <code>[python]&gt;=0.18</code> <code>0.22.0</code> ISC <code>mkdocstrings-python</code> A Python handler for mkdocstrings. <code>&gt;=0.5.2</code> <code>1.1.2</code> ISC <code>mypy</code> Optional static typing for Python <code>&gt;=0.910</code> <code>1.3.0</code> ? <code>mypy-extensions</code> Type system extensions for programs checked with the mypy type checker. <code>&gt;=0.4.3</code> <code>1.0.0</code> MIT License <code>numpy</code> Fundamental package for array computing in Python <code>1.24.3</code> BSD-3-Clause <code>packaging</code> Core utilities for Python packages <code>&gt;=22.0</code> <code>23.1</code> BSD License <code>pandas</code> Powerful data structures for data analysis, time series, and statistics <code>&gt;=0.18</code> <code>2.0.2</code> BSD License <code>pathspec</code> Utility library for gitignore style pattern matching of file paths. <code>&gt;=0.9.0</code> <code>0.11.1</code> Mozilla Public License 2.0 (MPL 2.0) <code>platformdirs</code> A small Python package for determining appropriate platform-specific dirs, e.g. a \"user data dir\". <code>&gt;=2</code> <code>3.5.3</code> MIT License <code>pluggy</code> plugin and hook calling mechanisms for python <code>&lt;2.0,&gt;=0.12</code> <code>1.0.0</code> MIT <code>ptyprocess</code> Run a subprocess in a pseudo terminal <code>~=0.6; sys_platform != \"win32\"</code> <code>0.7.0</code> ISC License (ISCL) <code>pygal</code> A Python svg graph plotting library <code>3.0.0</code> GNU LGPL v3+ <code>pygaljs</code> Python package providing assets from https://github.com/Kozea/pygal.js <code>1.0.2</code> LGPLv3 <code>pygments</code> Pygments is a syntax highlighting package written in Python. <code>&gt;=2.14</code> <code>2.15.1</code> BSD-2-Clause <code>pymdown-extensions</code> Extension pack for Python Markdown. <code>&gt;=9</code> <code>10.0.1</code> MIT License <code>pyrsistent</code> Persistent/Functional/Immutable data structures <code>!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0</code> <code>0.19.3</code> MIT <code>pytest</code> pytest: simple powerful testing with Python <code>&gt;=6.2</code> <code>7.3.2</code> MIT <code>pytest-benchmark</code> A <code>pytest</code> fixture for benchmarking code. It will group the tests into rounds that are calibrated to the chosen timer. <code>[histogram]&gt;=4</code> <code>4.0.0</code> BSD-2-Clause <code>pytest-cov</code> Pytest plugin for measuring coverage. <code>&gt;=3.0</code> <code>4.1.0</code> MIT <code>pytest-randomly</code> Pytest plugin to randomly order tests and control random.seed. <code>&gt;=3.10</code> <code>3.12.0</code> MIT <code>pytest-xdist</code> pytest xdist plugin for distributed testing, most importantly across multiple CPUs <code>&gt;=2.4</code> <code>3.3.1</code> MIT <code>python-dateutil</code> Extensions to the standard Python datetime module <code>&gt;=2.8.2</code> <code>2.8.2</code> Dual License <code>pytz</code> World timezone definitions, modern and historical <code>&gt;=2020.1</code> <code>2023.3</code> MIT <code>pyyaml</code> YAML parser and emitter for Python <code>&gt;=5.1</code> <code>6.0</code> MIT <code>pyyaml-env-tag</code> A custom YAML tag for referencing environment variables in YAML files. <code>&gt;=0.1</code> <code>0.1</code> MIT License <code>regex</code> Alternative regular expression module, to replace re. <code>&gt;=2022.4.24</code> <code>2023.6.3</code> Apache Software License <code>requests</code> Python HTTP for Humans. <code>&gt;=2.26</code> <code>2.31.0</code> Apache 2.0 <code>ruamel-yaml</code> ruamel.yaml is a YAML parser/emitter that supports roundtrip preservation of comments, seq/map flow style, and map key order <code>&gt;=0.17.21</code> <code>0.17.31</code> ? <code>ruamel-yaml-clib</code> C version of reader, parser and emitter for ruamel.yaml derived from libyaml <code>&gt;=0.2.7; platform_python_implementation == \"CPython\" and python_version &lt; \"3.12\"</code> <code>0.2.7</code> ? <code>ruff</code> An extremely fast Python linter, written in Rust. <code>&gt;=0.0.246</code> <code>0.0.272</code> ? <code>safety</code> Checks installed dependencies for known vulnerabilities and licenses. <code>&gt;=2</code> <code>2.3.4</code> ? <code>semver</code> Python helper for Semantic Versioning (http://semver.org/) <code>~=2.13</code> <code>2.13.0</code> ? <code>setuptools</code> Easily download, build, install, upgrade, and uninstall Python packages <code>&gt;=19.3</code> <code>67.8.0</code> ? <code>six</code> Python 2 and 3 compatibility utilities <code>&gt;=1.5</code> <code>1.16.0</code> MIT <code>toml</code> Python Library for Tom's Obvious, Minimal Language <code>&gt;=0.10</code> <code>0.10.2</code> MIT <code>tomli</code> A lil' TOML parser <code>&gt;=1.1.0; python_version &lt; \"3.11\"</code> <code>2.0.1</code> MIT License <code>toolz</code> List processing tools and functional utilities <code>0.12.0</code> BSD <code>types-markdown</code> Typing stubs for Markdown <code>&gt;=3.3</code> <code>3.4.2.9</code> ? <code>types-toml</code> Typing stubs for toml <code>&gt;=0.10</code> <code>0.10.8.6</code> ? <code>typing-extensions</code> Backported and Experimental Type Hints for Python 3.7+ <code>&gt;=4.0.1; python_version &lt; \"3.11\"</code> <code>4.6.3</code> Python Software Foundation License <code>tzdata</code> Provider of IANA time zone data <code>&gt;=2022.1</code> <code>2023.3</code> Apache-2.0 <code>urllib3</code> HTTP library with thread-safe connection pooling, file post, and more. <code>&lt;3,&gt;=1.21.1</code> <code>2.0.3</code> MIT License <code>watchdog</code> Filesystem events monitoring <code>&gt;=2.0</code> <code>3.0.0</code> Apache License 2.0 <code>zipp</code> Backport of pathlib-compatible object wrapper for zip files <code>&gt;=0.5</code> <code>3.15.0</code> MIT License"},{"location":"license/","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2023 Pierre Marijon\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"usages/","title":"VariantPlaner","text":"<p>variantplaner is a set of tools that converts a large set of vcf's into an interoperable data structure in an efficient way.</p> <p>To show the capabilities of the variant planner we will use a small example.</p>"},{"location":"usages/#setup","title":"Setup","text":"<p>This tutorial assume you are on unix like system, you have python setup and you install variantplaner</p> <p>Requirements list:</p> <ul> <li>curl</li> <li>gunzip</li> </ul> <p>Optional:</p> <ul> <li>pqrs</li> <li>gnu-parallel</li> </ul> <p>Quering dataset:</p> <ul> <li>polars-cli</li> <li>duckdb</li> </ul>"},{"location":"usages/#download-data","title":"Download data","text":"<pre><code>mkdir -p vp_tuto/vcf/\ncd vp_tuto\nURI_ROOT=\"https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release\"\ncurl ${URI_ROOT}/NA12878_HG001/latest/GRCh38/HG001_GRCh38_1_22_v4.2.1_benchmark.vcf.gz | gunzip - &gt; vcf/HG001.vcf\ncurl ${URI_ROOT}/AshkenazimTrio/HG002_NA24385_son/latest/GRCh38/HG002_GRCh38_1_22_v4.2.1_benchmark.vcf.gz | gunzip - &gt; vcf/HG002.vcf\ncurl ${URI_ROOT}/AshkenazimTrio/HG003_NA24149_father/latest/GRCh38/HG003_GRCh38_1_22_v4.2.1_benchmark.vcf.gz | gunzip - &gt; vcf/HG003.vcf\ncurl ${URI_ROOT}/AshkenazimTrio/HG004_NA24143_mother/latest/GRCh38/HG004_GRCh38_1_22_v4.2.1_benchmark.vcf.gz | gunzip - &gt; vcf/HG004.vcf\ncurl ${URI_ROOT}/ChineseTrio/HG006_NA24694_father/latest/GRCh38/HG006_GRCh38_1_22_v4.2.1_benchmark.vcf.gz | gunzip - &gt; vcf/HG006.vcf\ncurl ${URI_ROOT}/ChineseTrio/HG007_NA24695_mother/latest/GRCh38/HG007_GRCh38_1_22_v4.2.1_benchmark.vcf.gz | gunzip - &gt; vcf/HG007.vcf\n</code></pre>"},{"location":"usages/#variant-planner-presentation","title":"Variant planner presentation","text":"<p>variantplaner is a python module with command line tools, it is composed of several subcommands (they will be detailed later) but has two global options, one for parallelization and another for the level of verbosity you want. <pre><code>Usage: variantplaner [OPTIONS] COMMAND [ARGS]...\n\n  Run VariantPlanner.\n\nOptions:\n  -t, --threads INTEGER RANGE  Number of threads usable  [default: 1; x&gt;=0]\n  -v, --verbose                Verbosity level  [0&lt;=x&lt;=4]\n  --help                       Show this message and exit.\n\nCommands:\n  annotations  Convert an annotation variation file in parquet.\n  metadata     Convert an metadata file in parquet.\n  parquet2vcf  Convert parquet in vcf.\n  struct       Struct operation on parquet file.\n  vcf2parquet  Convert a vcf in parquet.\n</code></pre></p>"},{"location":"usages/#vcf2parquet","title":"vcf2parquet","text":"<p>First step is convert vcf data in parquet it's a column oriented format with better performance.</p> <p>We split vcf in two part on for variant information and another for genotype information.</p> <pre><code>mkdir -p variants genotypes/samples/\n</code></pre> <pre><code>for vcf_path in $(ls vcf/*.vcf)\ndo\nvcf_basename=$(basename ${vcf_path} .vcf)\nvariantplaner -t 4 vcf2parquet -i ${vcf_path} \\\n-v variants/${vcf_basename}.parquet \\\n-g genotypes/samples/${vcf_basename}.parquet \\\n-f GT:PS:DP:ADALL:AD:GQ\ndone\n</code></pre> gnu-parallel method <pre><code>find vcf -type f -name *.vcf -exec basename {} .vcf \\; | \\\nparallel variantplaner -t 2 vcf2parquet -i vcf/{}.vcf -v variants/{}.parquet \\\n-g genotypes/samples/{}.parquet -f GT:PS:DP:ADALL:AD:GQ\n</code></pre> <p>Parquet variants file contains 5 column:</p> <ul> <li>chr: Chromosome name, X -&gt; 22, Y -&gt; 23, MT -&gt; 24</li> <li>pos: Position of variant</li> <li>ref: Reference sequence</li> <li>alt: Alternative sequence</li> <li>id: An hash of other value colision isn't check but highly improbable check api documentation</li> </ul> variants parquet file content <p>You can inspect content of parquet file generate with pqrs <pre><code>pqrs head variants/HG001.parquet\n{id: 17886044532216650390, chr: 1, pos: 783006, ref: \"A\", alt: \"G\"}\n{id: 7513336577790240873, chr: 1, pos: 783175, ref: \"T\", alt: \"C\"}\n{id: 17987040642944149052, chr: 1, pos: 784860, ref: \"T\", alt: \"C\"}\n{id: 10342734968077036194, chr: 1, pos: 785417, ref: \"G\", alt: \"A\"}\n{id: 890514037559296207, chr: 1, pos: 797392, ref: \"G\", alt: \"A\"}\n</code></pre></p> <p>Parquet genotypes file contains column:</p> <ul> <li>id: Same as variant id</li> <li>gt: vcf GT value 1 -&gt; heterozygote 2 -&gt; homozygote (phasing information is lost)</li> <li>ps: Phase set in which this variant falls</li> <li>dp: vcf DP coverage of the variant for this sample</li> <li>adall: Net allele depths across all datasets</li> <li>ad: vcf AD per allele reads depth</li> <li>gq: vcf GQ quality of variant for this sample</li> </ul> genotypes parquet file content <p>You can inspect content of parquet file generate with pqrs <pre><code>pqrs head genotypes/HG001.parquet\n{id: 17886044532216650390, sample: \"HG001\", gt: 2, ps: null, dp: 652, adall: [16, 234], ad: [0, 82], gq: 312}\n{id: 7513336577790240873, sample: \"HG001\", gt: 2, ps: null, dp: 639, adall: [0, 218], ad: [0, 84], gq: 194}\n{id: 17987040642944149052, sample: \"HG001\", gt: 2, ps: null, dp: 901, adall: [105, 406], ad: [0, 74], gq: 301}\n{id: 10342734968077036194, sample: \"HG001\", gt: 2, ps: null, dp: 820, adall: [125, 383], ad: [0, 70], gq: 339}\n{id: 890514037559296207, sample: \"HG001\", gt: 1, ps: null, dp: 760, adall: [161, 142], ad: [25, 37], gq: 147}\n</code></pre></p>"},{"location":"usages/#structuration-of-data","title":"Structuration of data","text":""},{"location":"usages/#merge-all-variant","title":"Merge all variant","text":"<p>We can now aggregate all variant present in our dataset to perform this operation we use divide to conquer merge methode by generate temporary file. By default file are write in <code>/tmp</code> but you can control where these files are write by set <code>TMPDIR</code>, <code>TEMP</code> or <code>TMP</code> directory.</p> <pre><code>input=$(ls variants/ | xargs -I {} -x echo \"-i variants/\"{} | tr '\\n' ' ')\nvariantplaner -t 8 struct $(echo $input) variants -o variants.parquet\n</code></pre> <p>File <code>variants.parquet</code> containt all uniq variants present in dataset.</p>"},{"location":"usages/#genotypes-structuration","title":"Genotypes structuration","text":""},{"location":"usages/#by-samples","title":"By samples","text":"<p>This structurations data is already down in vcf2parquet setp check content of <code>genotypes/samples</code>: <pre><code>\u279c ls genotypes/samples\nHG001.parquet  HG002.parquet  HG003.parquet  HG004.parquet  HG006.parquet  HG007.parquet\n</code></pre></p>"},{"location":"usages/#by-variants","title":"By variants","text":"<pre><code>mkdir -p genotypes/variants/\ninput=$(ls genotypes/samples/ | xargs -I {} -x echo \"-i genotypes/samples/\"{} | tr '\\n' ' ')\nvariantplaner -t 8 struct $(echo $input) genotypes -p genotypes/variants/\n</code></pre> <p>All genotypes information are split in hive like structure to optimize request on data.</p>"},{"location":"usages/#add-annotations","title":"Add annotations","text":"<p>To work on your variant you probably need and annotations.</p>"},{"location":"usages/#snpeff-annotations","title":"Snpeff annotations","text":"<p>First convert your unique variants in parquet format (<code>variants.parquet</code>) in vcf: <pre><code>variantplaner -t 8 parquet2vcf -i variants.parquet -o variants.vcf\n</code></pre></p> <p><code>parquet2vcf</code> subcommand have many more option but we didn't need it now.</p> <p>Next annotate this <code>variants.vcf</code> with snpeff, we assume you generate a file call <code>variants.snpeff.vcf</code>.</p> <p>To convert annotated vcf in parquet, keep 'ANN' info column and rename vcf id column in snpeff_id you can run: <pre><code>variantplaner -t 8 annotations -i variants.snpeff.vcf -o snpeff.parquet vcf -i ANN -r snpeff_id\n</code></pre></p> <p>If you didn't set any value of option <code>-i</code> in vcf subsubcommand all info column are keep.</p>"},{"location":"usages/#clinvar-annotations","title":"Clinvar annotations","text":"<p>Download last clinvar version:</p> <pre><code>mkdir annotations\ncurl https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz \\\n| gunzip - &gt; annotations/clinvar.vcf\n</code></pre> <p>Convert clinvar vcf file in parquet file:</p> <pre><code>variantplaner annotations -i annotations/clinvar.vcf -o annotations/clinvar.parquet vcf -r clinvar_id\n</code></pre> <p>Parquet file produce contains many columns:</p> <ul> <li>clinvar_id: content of vcf id column if option <code>-r</code> is not set column name is <code>vid</code></li> <li>id: variantplaner id</li> <li>All INFO filed</li> </ul> <p>Annotations subcommand try to make match between vcf info type and parquet type.</p> <code>annotations/clinvar.parquet</code> file content <pre><code>pqrs head annotations/clinvar.parquet\n{clinvar_id: 2205837, id: 11650605831284591550, AF_ESP: null, AF_EXAC: null, AF_TGP: null, ALLELEID: 2193183, CLNDN: [\"Inborn_genetic_diseases\"], CLNDNINCL: null, CLNDISDB: [\"MeSH:D030342\", \"MedGen:C0950123\"], CLNDISDBINCL: null, CLNHGVS: [\"NC_000001.11:g.69134A&gt;G\"], CLNREVSTAT: [\"criteria_provided\", \"_single_submitter\"], CLNSIG: [\"Likely_benign\"], CLNSIGCONF: null, CLNSIGINCL: null, CLNVC: \"single_nucleotide_variant\", CLNVCSO: \"SO:0001483\", CLNVI: null, DBVARID: null, GENEINFO: \"OR4F5:79501\", MC: [\"SO:0001583|missense_variant\"], ORIGIN: [\"1\"], RS: null}\n{clinvar_id: 2252161, id: 2295086632353399847, AF_ESP: null, AF_EXAC: null, AF_TGP: null, ALLELEID: 2238986, CLNDN: [\"Inborn_genetic_diseases\"], CLNDNINCL: null, CLNDISDB: [\"MeSH:D030342\", \"MedGen:C0950123\"], CLNDISDBINCL: null, CLNHGVS: [\"NC_000001.11:g.69581C&gt;G\"], CLNREVSTAT: [\"criteria_provided\", \"_single_submitter\"], CLNSIG: [\"Uncertain_significance\"], CLNSIGCONF: null, CLNSIGINCL: null, CLNVC: \"single_nucleotide_variant\", CLNVCSO: \"SO:0001483\", CLNVI: null, DBVARID: null, GENEINFO: \"OR4F5:79501\", MC: [\"SO:0001583|missense_variant\"], ORIGIN: [\"1\"], RS: null}\n{clinvar_id: 2396347, id: 11033100074712141168, AF_ESP: null, AF_EXAC: null, AF_TGP: null, ALLELEID: 2386655, CLNDN: [\"Inborn_genetic_diseases\"], CLNDNINCL: null, CLNDISDB: [\"MeSH:D030342\", \"MedGen:C0950123\"], CLNDISDBINCL: null, CLNHGVS: [\"NC_000001.11:g.69682G&gt;A\"], CLNREVSTAT: [\"criteria_provided\", \"_single_submitter\"], CLNSIG: [\"Uncertain_significance\"], CLNSIGCONF: null, CLNSIGINCL: null, CLNVC: \"single_nucleotide_variant\", CLNVCSO: \"SO:0001483\", CLNVI: null, DBVARID: null, GENEINFO: \"OR4F5:79501\", MC: [\"SO:0001583|missense_variant\"], ORIGIN: [\"1\"], RS: null}\n{clinvar_id: 2288999, id: 10487392163259126218, AF_ESP: null, AF_EXAC: null, AF_TGP: null, ALLELEID: 2278803, CLNDN: [\"Inborn_genetic_diseases\"], CLNDNINCL: null, CLNDISDB: [\"MeSH:D030342\", \"MedGen:C0950123\"], CLNDISDBINCL: null, CLNHGVS: [\"NC_000001.11:g.69769T&gt;C\"], CLNREVSTAT: [\"criteria_provided\", \"_single_submitter\"], CLNSIG: [\"Uncertain_significance\"], CLNSIGCONF: null, CLNSIGINCL: null, CLNVC: \"single_nucleotide_variant\", CLNVCSO: \"SO:0001483\", CLNVI: null, DBVARID: null, GENEINFO: \"OR4F5:79501\", MC: [\"SO:0001583|missense_variant\"], ORIGIN: [\"1\"], RS: null}\n{clinvar_id: 2351346, id: 5356120651941363990, AF_ESP: null, AF_EXAC: null, AF_TGP: null, ALLELEID: 2333177, CLNDN: [\"Inborn_genetic_diseases\"], CLNDNINCL: null, CLNDISDB: [\"MeSH:D030342\", \"MedGen:C0950123\"], CLNDISDBINCL: null, CLNHGVS: [\"NC_000001.11:g.69995G&gt;C\"], CLNREVSTAT: [\"criteria_provided\", \"_single_submitter\"], CLNSIG: [\"Uncertain_significance\"], CLNSIGCONF: null, CLNSIGINCL: null, CLNVC: \"single_nucleotide_variant\", CLNVCSO: \"SO:0001483\", CLNVI: null, DBVARID: null, GENEINFO: \"OR4F5:79501\", MC: [\"SO:0001583|missense_variant\"], ORIGIN: [\"1\"], RS: null}\n</code></pre> <p>With option of subcommand vcf <code>-i</code> you can select which column are include in parquet file For example command: <pre><code>variantplaner annotations -i annotations/clinvar.vcf -o annotations/clinvar.parquet vcf -r clinvar_id -i ALLELEID -i CLNDN -i AF_ESP -i GENEINFO\n</code></pre></p> <p>Produce a <code>annotations/clinvar.parquet</code> with columns:</p> <ul> <li>clinvar_id</li> <li>id</li> <li>ALLELEID</li> <li>CLNDN</li> </ul> <code>annotations/clinvar.parquet</code> file content <pre><code>\u279c pqrs head annotations/clinvar.parquet\n{clinvar_id: 2205837, id: 11650605831284591550, ALLELEID: 2193183, CLNDN: [\"Inborn_genetic_diseases\"]}\n{clinvar_id: 2252161, id: 2295086632353399847, ALLELEID: 2238986, CLNDN: [\"Inborn_genetic_diseases\"]}\n{clinvar_id: 2396347, id: 11033100074712141168, ALLELEID: 2386655, CLNDN: [\"Inborn_genetic_diseases\"]}\n{clinvar_id: 2288999, id: 10487392163259126218, ALLELEID: 2278803, CLNDN: [\"Inborn_genetic_diseases\"]}\n{clinvar_id: 2351346, id: 5356120651941363990, ALLELEID: 2333177, CLNDN: [\"Inborn_genetic_diseases\"]}\n</code></pre>"},{"location":"usages/#querying","title":"Querying","text":"<p>You could use polars-cli or duckdb to interogate your variants database.</p>"},{"location":"usages/#polars-cli","title":"polars-cli","text":""},{"location":"usages/#count-variants","title":"Count variants","text":"<pre><code>\u3009select count(*) from read_parquet('variants.parquet');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count   \u2502\n\u2502 ---     \u2502\n\u2502 u32     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 7852699 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> check result with <code>pqrs</code> <p>We can check we have same result with pqrs</p> <pre><code>\u279c pqrs rowcount variants.parquet\nFile Name: variants.parquet: 7852699 rows\n</code></pre>"},{"location":"usages/#filter-variants-from-annotations","title":"Filter variants from annotations:","text":"<p>Get all variant with a AF_ESP upper than 0.9999</p> <pre><code>\u3009select chr, pos, ref, alt, AF_ESP from read_parquet('variants.parquet') as v left join read_parquet('annotations/clinvar.parquet') as c on c.id=v.id where AF_ESP&gt;0.9999;\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 chr \u2506 pos      \u2506 ref \u2506 alt \u2506 AF_ESP  \u2502\n\u2502 --- \u2506 ---      \u2506 --- \u2506 --- \u2506 ---     \u2502\n\u2502 u8  \u2506 u64      \u2506 str \u2506 str \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 10  \u2506 16901372 \u2506 G   \u2506 C   \u2506 0.99992 \u2502\n\u2502 11  \u2506 78121030 \u2506 T   \u2506 A   \u2506 0.99992 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usages/#get-sample-have-variant","title":"Get sample have variant","text":"<p>Get all variant and sample with GENEINFO equal to 'SAMD11:148398'</p> <pre><code>\u3009select distinct chr, pos, ref, alt, sample from read_parquet('variants.parquet') as v left join read_parquet('genotypes/samples/*') as g on v.id=g.id left join read_parquet('annotations/clinvar.parquet') as a on v.id=a.id WHERE GENEINFO='SAMD11:148398';\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 chr \u2506 pos    \u2506 ref \u2506 alt \u2506 sample \u2502\n\u2502 --- \u2506 ---    \u2506 --- \u2506 --- \u2506 ---    \u2502\n\u2502 u8  \u2506 u64    \u2506 str \u2506 str \u2506 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 942451 \u2506 T   \u2506 C   \u2506 HG003  \u2502\n\u2502 1   \u2506 942451 \u2506 T   \u2506 C   \u2506 HG001  \u2502\n\u2502 1   \u2506 942451 \u2506 T   \u2506 C   \u2506 HG007  \u2502\n\u2502 1   \u2506 942451 \u2506 T   \u2506 C   \u2506 HG004  \u2502\n\u2502 \u2026   \u2506 \u2026      \u2506 \u2026   \u2506 \u2026   \u2506 \u2026      \u2502\n\u2502 1   \u2506 942934 \u2506 G   \u2506 C   \u2506 HG003  \u2502\n\u2502 1   \u2506 943937 \u2506 C   \u2506 T   \u2506 HG004  \u2502\n\u2502 1   \u2506 942451 \u2506 T   \u2506 C   \u2506 HG002  \u2502\n\u2502 1   \u2506 942451 \u2506 T   \u2506 C   \u2506 HG006  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usages/#duckdb","title":"duckdb","text":""},{"location":"usages/#count-variants_1","title":"Count variants","text":"<pre><code>D select count(*) from read_parquet('variants.parquet');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count_star() \u2502\n\u2502    int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      7852699 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> check result with <code>pqrs</code> <p>We can check we have same result with pqrs</p> <pre><code>\u279c pqrs rowcount variants.parquet\nFile Name: variants.parquet: 7852699 rows\n</code></pre>"},{"location":"usages/#filter-variants-from-annotations_1","title":"Filter variants from annotations:","text":"<p>Get all variant with a AF_ESP upper than 0.9999</p> <pre><code>D select chr, pos, ref, alt, AF_ESP from read_parquet('variants.parquet') as v left join read_parquet('annotations/clinvar.parquet') as c on c.id=v.id where AF_ESP&gt;0.9999;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  chr  \u2502   pos    \u2502   ref   \u2502   alt   \u2502 AF_ESP  \u2502\n\u2502 uint8 \u2502  uint64  \u2502 varchar \u2502 varchar \u2502 double  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    10 \u2502 16901372 \u2502 G       \u2502 C       \u2502 0.99992 \u2502\n\u2502    11 \u2502 78121030 \u2502 T       \u2502 A       \u2502 0.99992 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usages/#get-sample-have-variant_1","title":"Get sample have variant","text":"<p>Get all variant and sample with GENEINFO equal to 'SAMD11:148398'</p> <pre><code>D select distinct chr, pos, ref, alt, sample from read_parquet('variants.parquet') as v left join read_parquet('genotypes/samples/*') as g on v.id=g.id left join read_parquet('annotations/clinvar.parquet') as a on v.id=a.id WHERE GENEINFO='SAMD11:148398';\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  chr  \u2502  pos   \u2502   ref   \u2502   alt   \u2502 sample  \u2502\n\u2502 uint8 \u2502 uint64 \u2502 varchar \u2502 varchar \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 942451 \u2502 T       \u2502 C       \u2502 HG002   \u2502\n\u2502     1 \u2502 942934 \u2502 G       \u2502 C       \u2502 HG002   \u2502\n\u2502     1 \u2502 942451 \u2502 T       \u2502 C       \u2502 HG003   \u2502\n\u2502     1 \u2502 942934 \u2502 G       \u2502 C       \u2502 HG003   \u2502\n\u2502     1 \u2502 942451 \u2502 T       \u2502 C       \u2502 HG007   \u2502\n\u2502     1 \u2502 943937 \u2502 C       \u2502 T       \u2502 HG007   \u2502\n\u2502     1 \u2502 942451 \u2502 T       \u2502 C       \u2502 HG001   \u2502\n\u2502     1 \u2502 942451 \u2502 T       \u2502 C       \u2502 HG004   \u2502\n\u2502     1 \u2502 943937 \u2502 C       \u2502 T       \u2502 HG004   \u2502\n\u2502     1 \u2502 942451 \u2502 T       \u2502 C       \u2502 HG006   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                            5 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/variantplaner/","title":"variantplaner","text":"<p>VariantPlaner.</p> <p>A tool kit to manage many variant without many cpu and ram ressource.</p> <p>Convert vcf in parquet, convert annotations in parquet, convert parquet in vcf. Build a file struct to get a fast variants database interogations time.</p>"},{"location":"reference/variantplaner/cli/","title":"cli","text":"<p>Module that contains the command line application.</p>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.annotations_csv","title":"annotations_csv","text":"<pre><code>annotations_csv(\n    ctx,\n    chromosome,\n    position,\n    reference,\n    alternative,\n    info,\n    separator=\",\",\n)\n</code></pre> <p>Convert an annotated csv in parquet.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@annotations_main.command(\"csv\")\n@click.pass_context\n@click.option(\n    \"-c\",\n    \"--chromosome\",\n    help=\"Name of chromosome column\",\n    type=str,\n    required=True,\n)\n@click.option(\n    \"-p\",\n    \"--position\",\n    help=\"Name of position column\",\n    type=str,\n    required=True,\n)\n@click.option(\n    \"-r\",\n    \"--reference\",\n    help=\"Name of reference column\",\n    type=str,\n    required=True,\n)\n@click.option(\n    \"-a\",\n    \"--alternative\",\n    help=\"Name of alternative column\",\n    type=str,\n    required=True,\n)\n@click.option(\n    \"-i\",\n    \"--info\",\n    multiple=True,\n    help=\"List of columns that are kept if this list is empty all columns are kept\",\n    type=str,\n)\n@click.option(\n    \"-s\",\n    \"--separator\",\n    help=\"Single byte character to use as delimiter in the file\",\n    type=str,\n    default=\",\",\n    show_default=True,\n)\ndef annotations_csv(\n    ctx: click.Context,\n    chromosome: str,\n    position: str,\n    reference: str,\n    alternative: str,\n    info: list[str],\n    separator: str = \",\",\n) -&gt; None:\n\"\"\"Convert an annotated csv in parquet.\"\"\"\n    logger = logging.getLogger(\"annotations-vcf\")\n\n    ctx.ensure_object(dict)\n\n    input_path = ctx.obj[\"input_path\"]\n    output_path = ctx.obj[\"output_path\"]\n\n    logger.debug(\n        f\"parameter: {input_path=} {output_path=} {chromosome=} {position=} {reference=} {alternative=} {info=}\",\n    )\n\n    lf = io.csv.into_lazyframe(\n        input_path,\n        chromosome,\n        position,\n        reference,\n        alternative,\n        info,\n        separator=separator,\n    )\n\n    lf = lf.drop([chromosome, position, reference, alternative])\n\n    lf.collect(streaming=True).write_parquet(output_path)\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.annotations_main","title":"annotations_main","text":"<pre><code>annotations_main(ctx, input_path, output_path)\n</code></pre> <p>Convert an annotation variation file in parquet.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@main.group(\"annotations\")\n@click.pass_context\n@click.option(\n    \"-i\",\n    \"--input-path\",\n    help=\"Path to input file\",\n    type=click.Path(exists=True, dir_okay=False, readable=True, allow_dash=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-o\",\n    \"--output-path\",\n    help=\"Path where variants annotations will be written in parquet\",\n    type=click.Path(writable=True, path_type=pathlib.Path),\n    required=True,\n)\ndef annotations_main(ctx: click.Context, input_path: pathlib.Path, output_path: pathlib.Path) -&gt; None:\n\"\"\"Convert an annotation variation file in parquet.\"\"\"\n    logger = logging.getLogger(\"annotations\")\n\n    ctx.obj = {\"input_path\": input_path, \"output_path\": output_path}\n\n    logger.debug(f\"parameter: {input_path=} {output_path=}\")\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.annotations_vcf","title":"annotations_vcf","text":"<pre><code>annotations_vcf(ctx, info=None, rename_id=None)\n</code></pre> <p>Convert an annotated vcf in parquet.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@annotations_main.command(\"vcf\")\n@click.pass_context\n@click.option(\n    \"-i\",\n    \"--info\",\n    multiple=True,\n    help=\"List of info fields that are kept if this list is empty all fields are kept only the first vcf file header is read\",\n    type=str,\n)\n@click.option(\n    \"-r\",\n    \"--rename-id\",\n    help=\"Set column name of variant id\",\n    type=str,\n)\ndef annotations_vcf(ctx: click.Context, info: set[str] | None = None, rename_id: str | None = None) -&gt; None:\n\"\"\"Convert an annotated vcf in parquet.\"\"\"\n    logger = logging.getLogger(\"annotations-vcf\")\n\n    ctx.ensure_object(dict)\n\n    input_path = ctx.obj[\"input_path\"]\n    output_path = ctx.obj[\"output_path\"]\n\n    logger.debug(f\"parameter: {input_path=} {output_path=} {info=}\")\n\n    try:\n        vcf_header = io.vcf.extract_header(input_path)\n        info_parser = io.vcf.info2expr(vcf_header, input_path, info)\n        lf = io.vcf.into_lazyframe(input_path)\n    except exception.NotAVCFError:\n        logger.exception(\"\")\n        sys.exit(21)\n\n    lf = lf.with_columns(info_parser).drop([\"chr\", \"pos\", \"ref\", \"alt\", \"filter\", \"qual\", \"info\"])\n\n    if rename_id:\n        logger.info(f\"Rename vcf variant id in {rename_id}\")\n        lf = lf.rename({\"vid\": rename_id})\n\n    lf.sink_parquet(output_path, compression=\"snappy\")\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.generate_main","title":"generate_main","text":"<pre><code>generate_main()\n</code></pre> <p>Subcommand generate thing.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@main.group(\"generate\")\ndef generate_main() -&gt; None:\n\"\"\"Subcommand generate thing.\"\"\"\n    logger = logging.getLogger(\"generate\")\n\n    logger.debug(\"parameter: \")\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.genotypes","title":"genotypes","text":"<pre><code>genotypes(ctx, prefix_path)\n</code></pre> <p>Convert set of genotype parquet in hive file.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@struct_main.command()\n@click.pass_context\n@click.option(\n    \"-p\",\n    \"--prefix-path\",\n    help=\"Path prefix\",\n    type=click.Path(file_okay=False, dir_okay=True, path_type=pathlib.Path),\n    required=True,\n)\ndef genotypes(ctx: click.Context, prefix_path: pathlib.Path) -&gt; None:\n\"\"\"Convert set of genotype parquet in hive file.\"\"\"\n    logger = logging.getLogger(\"struct.genotypes\")\n\n    ctx.ensure_object(dict)\n\n    input_paths = ctx.obj[\"input_paths\"]\n\n    threads = int(os.environ[\"POLARS_MAX_THREADS\"])\n    os.environ[\"POLARS_MAX_THREADS\"] = \"1\"\n\n    logger.debug(f\"parameter: {prefix_path=}\")\n\n    struct.genotypes.hive(input_paths, prefix_path, threads)\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.main","title":"main","text":"<pre><code>main(threads=1, verbose=0)\n</code></pre> <p>Run VariantPlanner.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@click.group(name=\"variantplaner\")\n@click.option(\"-t\", \"--threads\", help=\"Number of threads usable\", default=1, type=click.IntRange(0), show_default=True)\n@click.option(\"-v\", \"--verbose\", help=\"Verbosity level\", count=True, type=click.IntRange(0, 4))\ndef main(threads: int = 1, verbose: int = 0) -&gt; None:\n\"\"\"Run VariantPlanner.\"\"\"\n    logging.basicConfig(\n        style=\"{\",\n        format=\"{asctime} - {name}:{levelname}: {message}\",\n        encoding=\"utf-8\",\n        level=(4 - verbose) * 10,  # Python choose a bad logging levels order\n        stream=sys.stderr,\n    )\n\n    logger = logging.getLogger(\"main\")\n\n    logger.debug(f\"parameter: {threads=} {verbose=}\")\n\n    os.environ[\"POLARS_MAX_THREADS\"] = str(threads)\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.metadata","title":"metadata","text":"<pre><code>metadata(ctx, input_path, output_path)\n</code></pre> <p>Convert an metadata file in parquet.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@main.group()\n@click.pass_context\n@click.option(\n    \"-i\",\n    \"--input-path\",\n    help=\"Path to input file\",\n    type=click.Path(exists=True, dir_okay=False, readable=True, allow_dash=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-o\",\n    \"--output-path\",\n    help=\"Path where variants annotations will be written in parquet\",\n    type=click.Path(writable=True, path_type=pathlib.Path),\n    required=True,\n)\ndef metadata(ctx: click.Context, input_path: pathlib.Path, output_path: pathlib.Path) -&gt; None:\n\"\"\"Convert an metadata file in parquet.\"\"\"\n    logger = logging.getLogger(\"metadata\")\n\n    ctx.obj = {\"input_path\": input_path, \"output_path\": output_path}\n\n    logger.debug(f\"parameter: {input_path=} {output_path=}\")\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.metadata_csv","title":"metadata_csv","text":"<pre><code>metadata_csv(ctx, columns, separator=',')\n</code></pre> <p>Convert an metadata csv in parquet.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@metadata.command(\"csv\")\n@click.pass_context\n@click.option(\n    \"-c\",\n    \"--columns\",\n    multiple=True,\n    help=\"List of columns that are kept if this list is empty all columns are kept\",\n    type=str,\n)\n@click.option(\n    \"-s\",\n    \"--separator\",\n    help=\"Single byte character to use as delimiter in the file\",\n    type=str,\n    default=\",\",\n    show_default=True,\n)\ndef metadata_csv(ctx: click.Context, columns: list[str], separator: str = \",\") -&gt; None:\n\"\"\"Convert an metadata csv in parquet.\"\"\"\n    logger = logging.getLogger(\"metadata-csv\")\n\n    ctx.ensure_object(dict)\n\n    input_path = ctx.obj[\"input_path\"]\n    output_path = ctx.obj[\"output_path\"]\n\n    logger.debug(f\"parameter: {input_path=} {output_path=} {columns=}\")\n\n    lf = polars.scan_csv(input_path, separator=separator)\n\n    if columns:\n        lf = lf.select(columns)\n\n    lf.sink_parquet(output_path)\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.metadata_json","title":"metadata_json","text":"<pre><code>metadata_json(ctx, fields)\n</code></pre> <p>Convert an metadata json in parquet.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@metadata.command(\"json\")\n@click.pass_context\n@click.option(\n    \"-f\",\n    \"--fields\",\n    multiple=True,\n    help=\"List of fields that are kept if this list is empty all fields are kept\",\n    type=str,\n)\ndef metadata_json(ctx: click.Context, fields: list[str]) -&gt; None:\n\"\"\"Convert an metadata json in parquet.\"\"\"\n    logger = logging.getLogger(\"metadata-json\")\n\n    ctx.ensure_object(dict)\n\n    input_path = ctx.obj[\"input_path\"]\n    output_path = ctx.obj[\"output_path\"]\n\n    logger.debug(f\"parameter: {input_path=} {output_path=} {fields=}\")\n\n    lf = polars.read_json(input_path)\n\n    if fields:\n        lf = lf.select(fields)\n\n    lf.write_parquet(output_path)\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.parquet2vcf","title":"parquet2vcf","text":"<pre><code>parquet2vcf(\n    input_path,\n    output,\n    genotypes_path=None,\n    chromosome=\"chr\",\n    position=\"pos\",\n    identifier=\"id\",\n    reference=\"ref\",\n    alternative=\"alt\",\n    quality=None,\n    filter_col=None,\n    format_str=None,\n)\n</code></pre> <p>Convert parquet in vcf.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@main.command()\n@click.option(\n    \"-i\",\n    \"--input-path\",\n    help=\"Path to variants in parquet format\",\n    type=click.Path(exists=True, dir_okay=False, readable=True, allow_dash=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-g\",\n    \"--genotypes-path\",\n    help=\"Path to genotypes in parquet format\",\n    type=click.Path(exists=True, dir_okay=False, readable=True, path_type=pathlib.Path),\n)\n@click.option(\n    \"-o\",\n    \"--output\",\n    help=\"Path where the vcf is write\",\n    type=click.Path(dir_okay=False, writable=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-c\",\n    \"--chromosome\",\n    help=\"Name of chromosome column\",\n    type=str,\n    default=\"chr\",\n    show_default=True,\n)\n@click.option(\n    \"-p\",\n    \"--position\",\n    help=\"Name of position column\",\n    type=str,\n    default=\"pos\",\n    show_default=True,\n)\n@click.option(\n    \"-I\",\n    \"--identifier\",\n    help=\"Name of identity column\",\n    type=str,\n    default=\"id\",\n    show_default=True,\n)\n@click.option(\n    \"-r\",\n    \"--reference\",\n    help=\"Name of reference column\",\n    default=\"ref\",\n    show_default=True,\n)\n@click.option(\n    \"-a\",\n    \"--alternative\",\n    help=\"Name of alternative column\",\n    default=\"alt\",\n    show_default=True,\n)\n@click.option(\n    \"-q\",\n    \"--quality\",\n    help=\"Name of quality column\",\n    type=str,\n)\n@click.option(\n    \"-f\",\n    \"--filter\",\n    \"filter_col\",\n    help=\"Name of filter column\",\n    type=str,\n)\n@click.option(\n    \"-F\",\n    \"--format\",\n    \"format_str\",\n    help=\"Value of format column\",\n    type=str,\n)\ndef parquet2vcf(\n    input_path: pathlib.Path,\n    output: pathlib.Path,\n    genotypes_path: pathlib.Path | None = None,\n    chromosome: str = \"chr\",\n    position: str = \"pos\",\n    identifier: str = \"id\",\n    reference: str = \"ref\",\n    alternative: str = \"alt\",\n    quality: str | None = None,\n    filter_col: str | None = None,\n    format_str: str | None = None,\n) -&gt; None:\n\"\"\"Convert parquet in vcf.\"\"\"\n    logger = logging.getLogger(\"parquet2vcf\")\n\n    logger.debug(f\"parameter: {input_path=} {output=}\")\n\n    variants_lf = polars.scan_parquet(input_path)\n\n    if genotypes_path and format_str:\n        genotypes_lf = polars.scan_parquet(genotypes_path)\n        sample_name = genotypes_lf.select(\"sample\").collect().get_column(\"sample\").to_list()\n        merge_lf = extract.merge_variants_genotypes(variants_lf, genotypes_lf, sample_name)\n        sample2vcf_col2polars_col: dict[str, dict[str, str]] = {}\n        for sample in sample_name:\n            sample2vcf_col2polars_col[sample] = {}\n            for format_col in format_str.split(\":\"):\n                sample2vcf_col2polars_col[sample][format_col] = f\"{sample}_{format_col.lower()}\"\n\n        io.vcf.from_lazyframe(\n            merge_lf,\n            output,\n            io.vcf.build_rename_column(\n                chromosome,\n                position,\n                identifier,\n                reference,\n                alternative,\n                quality,\n                filter_col,\n                [],\n                format_str,\n                sample2vcf_col2polars_col,\n            ),\n        )\n    else:\n        io.vcf.from_lazyframe(\n            variants_lf,\n            output,\n            io.vcf.build_rename_column(\n                chromosome,\n                position,\n                identifier,\n                reference,\n                alternative,\n                quality,\n                filter_col,\n            ),\n        )\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.struct_main","title":"struct_main","text":"<pre><code>struct_main(ctx, input_paths)\n</code></pre> <p>Struct operation on parquet file.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@main.group(\"struct\")\n@click.pass_context\n@click.option(\n    \"-i\",\n    \"--input-paths\",\n    help=\"Paths of the variant files to be merged\",\n    multiple=True,\n    type=click.Path(exists=True, dir_okay=False, readable=True, path_type=pathlib.Path),\n    required=True,\n)\ndef struct_main(ctx: click.Context, input_paths: list[pathlib.Path]) -&gt; None:\n\"\"\"Struct operation on parquet file.\"\"\"\n    logger = logging.getLogger(\"struct\")\n\n    ctx.obj = {\"input_paths\": input_paths}\n\n    logger.debug(f\"parameter: {input_paths=}\")\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.transmission","title":"transmission","text":"<pre><code>transmission(\n    input_path,\n    ped_path,\n    index,\n    mother,\n    father,\n    transmission_path,\n)\n</code></pre> <p>Generate transmission information.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@generate_main.command(\"transmission\")\n@click.option(\n    \"-i\",\n    \"--input-path\",\n    help=\"Path genotypes parquet file\",\n    type=click.Path(exists=True, dir_okay=False, readable=True, allow_dash=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-p\",\n    \"--ped-path\",\n    help=\"Path to the ped file\",\n    type=click.Path(exists=True, dir_okay=False, readable=True, path_type=pathlib.Path),\n)\n@click.option(\n    \"-I\",\n    \"--index\",\n    help=\"Sample name of index\",\n    type=str,\n)\n@click.option(\n    \"-m\",\n    \"--mother\",\n    help=\"Sample name of mother\",\n    type=str,\n)\n@click.option(\n    \"-f\",\n    \"--father\",\n    help=\"Sample name of father\",\n    type=str,\n)\n@click.option(\n    \"-t\",\n    \"--transmission-path\",\n    help=\"Path transmission mode will be store\",\n    type=click.Path(dir_okay=False, writable=True, path_type=pathlib.Path),\n)\ndef transmission(\n    input_path: pathlib.Path,\n    ped_path: pathlib.Path | None,\n    index: str | None,\n    mother: str | None,\n    father: str | None,\n    transmission_path: pathlib.Path,\n) -&gt; None:\n\"\"\"Generate transmission information.\"\"\"\n    logger = logging.getLogger(\"generate-origin\")\n\n    logger.debug(f\"parameter: {input_path=} {ped_path=} {index=} {mother=} {father=} {transmission_path=}\")\n\n    genotypes_lf = polars.scan_parquet(input_path)\n\n    if ped_path:\n        ped_lf = io.ped.into_lazyframe(ped_path)\n        transmission_lf = generate.transmission_ped(genotypes_lf, ped_lf)\n    elif index and mother and father:\n        transmission_lf = generate.transmission(genotypes_lf, index, mother, father)\n    else:\n        logging.error(\"You must specify ped file or index, mother and father sample name\")\n        sys.exit(31)\n\n    transmission_lf.write_parquet(transmission_path)\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.variants","title":"variants","text":"<pre><code>variants(ctx, output_path, bytes_memory_limit=10000000000)\n</code></pre> <p>Merge multiple variants parquet file in one.</p> <p>If you set TMPDIR, TEMP or TMP environment variable you can control where temp file is create.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@struct_main.command()\n@click.pass_context\n@click.option(\n    \"-o\",\n    \"--output-path\",\n    help=\"Path where merged variants will be written\",\n    type=click.Path(writable=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-b\",\n    \"--bytes-memory-limit\",\n    help=\"Number of bytes used to build chunk of merge file\",\n    type=click.IntRange(0),\n    show_default=True,\n    default=10_000_000_000,\n)\ndef variants(ctx: click.Context, output_path: pathlib.Path, bytes_memory_limit: int = 10_000_000_000) -&gt; None:\n\"\"\"Merge multiple variants parquet file in one.\n\n    If you set TMPDIR, TEMP or TMP environment variable you can control where temp file is create.\n    \"\"\"\n    logger = logging.getLogger(\"struct.variants\")\n\n    ctx.ensure_object(dict)\n\n    input_paths = ctx.obj[\"input_paths\"]\n\n    logger.debug(f\"parameter: {output_path=} {bytes_memory_limit}\")\n\n    struct.variants.merge(input_paths, output_path, bytes_memory_limit)\n</code></pre>"},{"location":"reference/variantplaner/cli/#variantplaner.cli.vcf2parquet","title":"vcf2parquet","text":"<pre><code>vcf2parquet(\n    input_path,\n    variants,\n    genotypes,\n    annotations,\n    format_string=\"GT:AD:DP:GQ\",\n)\n</code></pre> <p>Convert a vcf in parquet.</p> Source code in <code>src/variantplaner/cli.py</code> <pre><code>@main.command()\n@click.option(\n    \"-i\",\n    \"--input-path\",\n    help=\"Path to vcf input file\",\n    type=click.Path(exists=True, dir_okay=False, readable=True, allow_dash=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-v\",\n    \"--variants\",\n    help=\"Path where the variants will be written in parquet\",\n    type=click.Path(dir_okay=False, writable=True, path_type=pathlib.Path),\n    required=True,\n)\n@click.option(\n    \"-g\",\n    \"--genotypes\",\n    help=\"Path where the genotypes will be written in parquet\",\n    type=click.Path(dir_okay=False, writable=True, path_type=pathlib.Path),\n)\n@click.option(\n    \"-a\",\n    \"--annotations\",\n    help=\"Path where the annotations will be written in parquet (if no info file is empty)\",\n    type=click.Path(dir_okay=False, writable=True, path_type=pathlib.Path),\n)\n@click.option(\n    \"-f\",\n    \"--format-string\",\n    help=\"Value of FORMAT column, line not match with this are ignored\",\n    type=str,\n    default=\"GT:AD:DP:GQ\",\n    show_default=True,\n)\ndef vcf2parquet(\n    input_path: pathlib.Path,\n    variants: pathlib.Path,\n    genotypes: pathlib.Path | None,\n    annotations: pathlib.Path | None,\n    format_string: str = \"GT:AD:DP:GQ\",\n) -&gt; None:\n\"\"\"Convert a vcf in parquet.\"\"\"\n    logger = logging.getLogger(\"vcf2parquet\")\n\n    logger.debug(f\"parameter: {input_path=} {variants=} {genotypes=}\")\n\n    try:\n        vcf_header = io.vcf.extract_header(input_path)\n    except exception.NotAVCFError:\n        logger.exception(\"\")\n        sys.exit(11)\n\n    # Read vcf and manage structural variant\n    lf = io.vcf.into_lazyframe(input_path, extension=io.vcf.IntoLazyFrameExtension.MANAGE_SV)\n\n    extract.variants(lf).sink_parquet(variants)\n    logger.info(f\"finish write {variants}\")\n\n    if genotypes:\n        try:\n            genotypes_lf = extract.genotypes(lf, io.vcf.format2expr(vcf_header, input_path), format_string)\n        except exception.NoGenotypeError:\n            logger.exception(\"\")\n            sys.exit(12)\n\n        genotypes_lf.sink_parquet(genotypes)\n\n    if annotations:\n        annotations_lf = lf.with_columns(io.vcf.info2expr(vcf_header, input_path))\n        annotations_lf = annotations_lf.drop([\"chr\", \"pos\", \"ref\", \"alt\", \"filter\", \"qual\", \"info\"])\n        annotations_lf.sink_parquet(annotations)\n\n    logger.info(f\"finish write {genotypes}\")\n</code></pre>"},{"location":"reference/variantplaner/exception/","title":"exception","text":"<p>All custom exception could be generate by VariantPlanner.</p>"},{"location":"reference/variantplaner/exception/#variantplaner.exception.NoGTError","title":"NoGTError","text":"<pre><code>NoGTError(message)\n</code></pre> <p>         Bases: <code>Exception</code></p> <p>Exception raise if genotype polars.LazyFrame not contains gt column.</p> Source code in <code>src/variantplaner/exception.py</code> <pre><code>def __init__(self, message: str):\n\"\"\"Initialize no gt error.\"\"\"\n    super().__init__(f\"In {message} gt column is missing.\")\n</code></pre>"},{"location":"reference/variantplaner/exception/#variantplaner.exception.NoGenotypeError","title":"NoGenotypeError","text":"<pre><code>NoGenotypeError()\n</code></pre> <p>         Bases: <code>Exception</code></p> <p>Exception raise if vcf file seems not contains genotypes information.</p> Source code in <code>src/variantplaner/exception.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize no genotype error.\"\"\"\n    super().__init__(\"LazyFrame seems not contains genotypes.\")\n</code></pre>"},{"location":"reference/variantplaner/exception/#variantplaner.exception.NotAVCFError","title":"NotAVCFError","text":"<pre><code>NotAVCFError(path)\n</code></pre> <p>         Bases: <code>Exception</code></p> <p>Exception raise if file read seems not be a vcf, generaly not contains a line starts with '#CHROM'.</p> Source code in <code>src/variantplaner/exception.py</code> <pre><code>def __init__(self, path: pathlib.Path):\n\"\"\"Initialize not a vcf error.\"\"\"\n    super().__init__(f\"File {path} seems not be a valid vcf file.\")\n</code></pre>"},{"location":"reference/variantplaner/extract/","title":"extract","text":"<p>Function to extract information of polars.LazyFrame produce by raw vcf file.</p>"},{"location":"reference/variantplaner/extract/#variantplaner.extract.genotypes","title":"genotypes","text":"<pre><code>genotypes(lf, col2expr, format_str='GT:AD:DP:GQ')\n</code></pre> <p>Extract genotypes information of raw polars.LazyFrame.</p> <p>Only line with format value match <code>format_str</code> are consider.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>polars.LazyFrame</code> <p>The target lazyframe</p> required <code>col2expr</code> <code>dict[str, Callable[[polars.Expr, str], polars.Expr]]</code> <p>A dict associate column name and function to apply to create polars.LazyFrame column (produce by io.vcf.format2expr)</p> required <code>format_str</code> <code>str</code> <p>Only variants match with this string format are considere</p> <code>'GT:AD:DP:GQ'</code> <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>A polars.LazyFrame with variant id, sample information and genotypes information</p> <p>Raises:</p> Type Description <code>NoGenotypeError</code> <p>If none of the lf columns is equal to FORMAT</p> Source code in <code>src/variantplaner/extract.py</code> <pre><code>def genotypes(\n    lf: polars.LazyFrame,\n    col2expr: dict[str, Callable[[polars.Expr, str], polars.Expr]],\n    format_str: str = \"GT:AD:DP:GQ\",\n) -&gt; polars.LazyFrame:\n\"\"\"Extract genotypes information of raw polars.LazyFrame.\n\n    Only line with format value match `format_str` are consider.\n\n    Args:\n        lf: The target lazyframe\n        col2expr: A dict associate column name and function to apply to create polars.LazyFrame column (produce by io.vcf.format2expr)\n        format_str: Only variants match with this string format are considere\n\n    Returns:\n        A polars.LazyFrame with variant id, sample information and genotypes information\n\n    Raises:\n        NoGenotypeError: If none of the lf columns is equal to FORMAT\n    \"\"\"\n    if \"format\" not in lf.columns:\n        raise NoGenotypeError\n\n    lf = lf.select([*lf.columns[lf.columns.index(\"format\") :]])\n\n    # Clean bad variant\n    lf = lf.filter(polars.col(\"format\").str.starts_with(format_str))\n\n    # Found index of genotype value\n    col_index = {\n        key: index\n        for (index, key) in enumerate(\n            format_str.split(\":\"),\n        )\n    }\n\n    # Pivot value\n    genotypes = lf.melt(id_vars=[\"id\"]).with_columns(\n        [\n            polars.col(\"id\"),\n            polars.col(\"variable\").alias(\"sample\"),\n            polars.col(\"value\").str.split(\":\"),\n        ],\n    )\n\n    # Split genotype column in sub value\n    genotypes = genotypes.with_columns(\n        [polars.col(\"value\").list.get(index).pipe(function=col2expr[col], name=col) for col, index in col_index.items()],  # type: ignore # noqa: PGH003\n    )\n\n    # Select intrusting column\n    genotypes = genotypes.select([\"id\", \"sample\", *[col.lower() for col in col_index]])\n\n    if \"gt\" in genotypes.columns:\n        return genotypes.filter(polars.col(\"gt\") != 0)\n\n    return genotypes\n</code></pre>"},{"location":"reference/variantplaner/extract/#variantplaner.extract.merge_variants_genotypes","title":"merge_variants_genotypes","text":"<pre><code>merge_variants_genotypes(\n    variants_lf, genotypes_lf, sample_name\n)\n</code></pre> <p>Merge variants and genotypes lazyframe.</p> <p>Parameters:</p> Name Type Description Default <code>variants_lf</code> <code>polars.LazyFrame</code> <p>lazyframe with variants, column: (id, chr, pos, ref, alt).</p> required <code>genotypes_lf</code> <code>polars.LazyFrame</code> <p>lazyframe with genotypes, column: (id, sample, [genotype column]).</p> required <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>A lazyframe with all data</p> Source code in <code>src/variantplaner/extract.py</code> <pre><code>def merge_variants_genotypes(\n    variants_lf: polars.LazyFrame,\n    genotypes_lf: polars.LazyFrame,\n    sample_name: list[str],\n) -&gt; polars.LazyFrame:\n\"\"\"Merge variants and genotypes lazyframe.\n\n    Args:\n       variants_lf: lazyframe with variants, column: (id, chr, pos, ref, alt).\n       genotypes_lf: lazyframe with genotypes, column: (id, sample, [genotype column]).\n\n    Returns:\n        A lazyframe with all data\n    \"\"\"\n    for sample in sample_name:\n        geno2sample = (\n            genotypes_lf.filter(polars.col(\"sample\") == sample)\n            .rename(\n                {col: f\"{sample}_{col}\" for col in genotypes_lf.columns[2:]},\n            )\n            .drop(\"sample\")\n        )\n        variants_lf = variants_lf.join(geno2sample, on=\"id\", how=\"outer\")\n\n    return variants_lf\n</code></pre>"},{"location":"reference/variantplaner/extract/#variantplaner.extract.variants","title":"variants","text":"<pre><code>variants(lf)\n</code></pre> <p>Extract variants only information of lazyframe.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>polars.LazyFrame</code> <p>A lazyframe</p> required <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>A lazyframe with just variant information (id, chr, pos, ref, alt)</p> Source code in <code>src/variantplaner/extract.py</code> <pre><code>def variants(lf: polars.LazyFrame) -&gt; polars.LazyFrame:\n\"\"\"Extract variants only information of lazyframe.\n\n    Args:\n        lf: A lazyframe\n\n    Returns:\n        A lazyframe with just variant information (id, chr, pos, ref, alt)\n    \"\"\"\n    return lf.select(\n        [\n            polars.col(\"id\"),\n            polars.col(\"chr\"),\n            polars.col(\"pos\"),\n            polars.col(\"ref\"),\n            polars.col(\"alt\"),\n        ],\n    )\n</code></pre>"},{"location":"reference/variantplaner/generate/","title":"generate","text":"<p>Function to generate information.</p>"},{"location":"reference/variantplaner/generate/#variantplaner.generate.transmission","title":"transmission","text":"<pre><code>transmission(\n    genotypes_lf, index_name, mother_name, father_name\n)\n</code></pre> <p>Compute how each variant are transmite to index case.</p> <p>Parameters:</p> Name Type Description Default <code>genotypes_lf</code> <code>polars.LazyFrame</code> <p>Genotypes polars.LazyFrame, <code>gt</code> column are required.</p> required <code>index_name</code> <code>str</code> <p>Sample name of index case.</p> required <code>mother_name</code> <code>str</code> <p>Sample name of mother.</p> required <code>father_name</code> <code>str</code> <p>Sample name of father.</p> required <p>Returns:</p> Name Type Description <code>polars.DataFrame</code> <p>DataFrame with transmission information.</p> <code>polars.DataFrame</code> <p>With genotyping information for index, mother and father.</p> <code>polars.DataFrame</code> <p>If any of them isn't present value are set to polars.Null (3 for gt)</p> <code>polars.DataFrame</code> <p>Columns transmission contains: index_gt * 100 + mother_gt * 10 + father_gt.</p> <code>Transmission</code> <code>polars.DataFrame</code> <p>230 mean homozygote variant not present in father but with no information about mother</p> <p>Raises:</p> Type Description <code>NoGTError</code> <p>if genotypes_lf not containts gt column.</p> Source code in <code>src/variantplaner/generate.py</code> <pre><code>def transmission(\n    genotypes_lf: polars.LazyFrame,\n    index_name: str,\n    mother_name: str,\n    father_name: str,\n) -&gt; polars.DataFrame:\n\"\"\"Compute how each variant are transmite to index case.\n\n    Args:\n        genotypes_lf: Genotypes polars.LazyFrame, `gt` column are required.\n        index_name: Sample name of index case.\n        mother_name: Sample name of mother.\n        father_name: Sample name of father.\n\n    Returns:\n         DataFrame with transmission information.\n         With genotyping information for index, mother and father.\n         If any of them isn't present value are set to polars.Null (3 for gt)\n         Columns transmission contains: index_gt * 100 + mother_gt * 10 + father_gt.\n         Transmission: 230 mean homozygote variant not present in father but with no information about mother\n\n    Raises:\n        NoGTError: if genotypes_lf not containts gt column.\n    \"\"\"\n    genotypes_column = list(genotypes_lf.columns[2:])\n    if \"gt\" not in genotypes_column:\n        raise NoGTError(\"genotype polars.LazyFrame\")\n\n    group_lf = genotypes_lf.groupby(\"id\").all().collect()\n    group_lf = group_lf.filter(polars.col(\"sample\").list.contains(index_name))\n\n    logger.debug(f\"{group_lf.row(0)}\")\n\n    # I assume sample order is all time the same but I'm not sure\n    sample2index = {sample: idx for idx, sample in enumerate(group_lf.row(0)[1], start=0)}\n\n    logger.debug(f\"{sample2index}\")\n\n    transmission_lf = group_lf.with_columns(\n        [polars.col(col).list.get(sample2index[index_name]).alias(f\"index_{col}\") for col in genotypes_column],\n    )\n\n    if mother_name in sample2index:\n        transmission_lf = transmission_lf.with_columns(\n            [polars.col(col).list.get(sample2index[mother_name]).alias(f\"mother_{col}\") for col in genotypes_column],\n        )\n    else:\n        transmission_lf = transmission_lf.with_columns(\n            [\n                polars.lit(3).alias(\"mother_gt\"),\n                *[polars.lit(None).alias(f\"mother_{col}\") for col in genotypes_column if col != \"gt\"],\n            ],\n        )\n\n    if father_name in sample2index:\n        transmission_lf = transmission_lf.with_columns(\n            [polars.col(col).list.get(sample2index[father_name]).alias(f\"father_{col}\") for col in genotypes_column],\n        )\n    else:\n        transmission_lf = transmission_lf.with_columns(\n            [\n                polars.lit(3).alias(\"father_gt\"),\n                *[polars.lit(None).alias(f\"father_{col}\") for col in genotypes_column if col != \"gt\"],\n            ],\n        )\n\n    transmission_lf = transmission_lf.with_columns(\n        (polars.col(\"index_gt\") * 100 + polars.col(\"mother_gt\") * 10 + polars.col(\"father_gt\"))\n        .cast(polars.UInt8)\n        .alias(\"origin\"),\n    )\n\n    transmission_lf = transmission_lf.drop([\"sample\", *genotypes_column])\n\n    return transmission_lf\n</code></pre>"},{"location":"reference/variantplaner/generate/#variantplaner.generate.transmission_ped","title":"transmission_ped","text":"<pre><code>transmission_ped(genotypes_lf, pedigree_lf)\n</code></pre> <p>Compute transmission of each variants.</p> <p>Warning: only the first sample with two parent are consider.</p> <p>Parameters:</p> Name Type Description Default <code>genotypes_lf</code> <code>polars.LazyFrame</code> <p>Genotypes LazyFrame, <code>gt</code> column are required.</p> required <code>pedigree_lf</code> <code>polars.LazyFrame</code> <p>Pedigree LazyFrame.</p> required <p>Returns:</p> Type Description <code>polars.DataFrame</code> <p>DataFrame with transmission information</p> <p>Raises:</p> Type Description <code>NoGTError</code> <p>if genotypes_lf not containts gt column.</p> Source code in <code>src/variantplaner/generate.py</code> <pre><code>def transmission_ped(\n    genotypes_lf: polars.LazyFrame,\n    pedigree_lf: polars.LazyFrame,\n) -&gt; polars.DataFrame:\n\"\"\"Compute transmission of each variants.\n\n    **Warning**: only the first sample with two parent are consider.\n\n    Args:\n        genotypes_lf: Genotypes LazyFrame, `gt` column are required.\n        pedigree_lf: Pedigree LazyFrame.\n\n    Returns:\n         DataFrame with transmission information\n\n    Raises:\n        NoGTError: if genotypes_lf not containts gt column.\n    \"\"\"\n    pedigree_lf = pedigree_lf.filter(polars.col(\"father_id\") != \"unknow\").filter(polars.col(\"mother_id\") != \"unknow\")\n\n    familly_info = pedigree_lf.collect().row(0, named=True)\n\n    return transmission(genotypes_lf, familly_info[\"personal_id\"], familly_info[\"mother_id\"], familly_info[\"father_id\"])\n</code></pre>"},{"location":"reference/variantplaner/normalization/","title":"normalization","text":"<p>Function use to normalize data.</p>"},{"location":"reference/variantplaner/normalization/#variantplaner.normalization.add_variant_id","title":"add_variant_id","text":"<pre><code>add_variant_id(lf)\n</code></pre> <p>Add a column id of variants.</p> <p>This id is compute by 64 bit hash on chromosome, position, reference sequence and alternative sequence. If lf.columns contains SVTYPE and SVLEN variant with regex group in alt &lt;([^:]+):anything:weird&gt; match SVTYPE are replace by concatenation of SVTYPE and SVLEN first value.</p> Colision risk <ul> <li>human genome size: 3,117,275,501 bp</li> <li>number of variant if each base have all sustitution 3,117,275,501 * 4 = 12,469,102,004 12,469,102,004 / 2^64 = 6.7595137e-10</li> </ul> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>polars.LazyFrame</code> <p>LazyFrame contains chr, pos, ref, alt columns</p> required <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>LazyFrame with chr column normalized</p> Source code in <code>src/variantplaner/normalization.py</code> <pre><code>def add_variant_id(lf: polars.LazyFrame) -&gt; polars.LazyFrame:\n\"\"\"Add a column id of variants.\n\n    This id is compute by 64 bit hash on chromosome, position, reference sequence and alternative sequence.\n    If lf.columns contains SVTYPE and SVLEN variant with regex group in alt &lt;([^:]+):anything:weird&gt; match SVTYPE are replace by concatenation of SVTYPE and SVLEN first value.\n\n    Colision risk:\n        - human genome size: 3,117,275,501 bp\n        - number of variant if each base have all sustitution 3,117,275,501 * 4 = 12,469,102,004\n        12,469,102,004 / 2^64 = 6.7595137e-10\n\n    Args:\n        lf: LazyFrame contains chr, pos, ref, alt columns\n\n    Returns:\n        LazyFrame with chr column normalized\n    \"\"\"\n    if \"SVTYPE\" in lf.columns and \"SVLEN\" in lf.columns:\n        lf = lf.with_columns(\n            polars.when(\n                polars.col(\"alt\").str.replace(\"&lt;(?&lt;type&gt;[^:]+).*&gt;\", \"$type\") == polars.col(\"SVTYPE\"),\n            )\n            .then(\n                polars.col(\"alt\").str.replace(\n                    \".+\",\n                    polars.concat_str(\n                        [polars.col(\"SVTYPE\"), polars.col(\"SVLEN\").list.get(0)],\n                        separator=\"-\",\n                    ),\n                ),\n            )\n            .otherwise(\n                polars.col(\"alt\"),\n            ),\n        )\n\n    return lf.with_columns(\n        polars.concat_str(\n            [\n                polars.col(\"chr\"),\n                polars.lit(\"-\"),\n                polars.col(\"pos\"),\n                polars.lit(\"-\"),\n                polars.col(\"ref\"),\n                polars.lit(\"-\"),\n                polars.col(\"alt\"),\n            ],\n        )\n        .hash()\n        .alias(\"id\"),\n    )\n</code></pre>"},{"location":"reference/variantplaner/normalization/#variantplaner.normalization.chromosome2integer","title":"chromosome2integer","text":"<pre><code>chromosome2integer(lf)\n</code></pre> <p>Convert chromosome string in number.</p> Chromosome name mapping table <ul> <li>X:  23</li> <li>Y:  24</li> <li> <p>Mt</p> <p>25</p> </li> </ul> <p>If chromosome value can't be convert in number row is remove.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>polars.LazyFrame</code> <p>LazyFrame contains chr column</p> required <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>LazyFrame with chr column normalized</p> Source code in <code>src/variantplaner/normalization.py</code> <pre><code>def chromosome2integer(lf: polars.LazyFrame) -&gt; polars.LazyFrame:\n\"\"\"Convert chromosome string in number.\n\n    Chromosome name mapping table:\n      - X:  23\n      - Y:  24\n      - MT: 25\n\n    If chromosome value can't be convert in number row is remove.\n\n    Args:\n        lf: LazyFrame contains chr column\n\n    Returns:\n        LazyFrame with chr column normalized\n\n    \"\"\"\n    lf = lf.with_columns(\n        [\n            polars.col(\"chr\")\n            .str.replace(\"chr\", \"\")\n            .str.replace(\"X\", \"23\")\n            .str.replace(\"Y\", \"24\")\n            .str.replace(\"MT\", \"25\")\n            .str.parse_int(10, strict=False)\n            .cast(polars.UInt8),\n            polars.col(\"pos\").cast(polars.UInt64),\n        ],\n    )\n\n    return lf.filter(~polars.col(\"chr\").is_null())\n</code></pre>"},{"location":"reference/variantplaner/io/","title":"io","text":"<p>Module manage input and output.</p>"},{"location":"reference/variantplaner/io/csv/","title":"csv","text":"<p>Function to manage input and output of csv file.</p>"},{"location":"reference/variantplaner/io/csv/#variantplaner.io.csv.ScanCsv","title":"ScanCsv","text":"<p>         Bases: <code>typing.TypedDict</code></p> <p>A struct to check type of parameter give to polars.scan_csv.</p>"},{"location":"reference/variantplaner/io/csv/#variantplaner.io.csv.into_lazyframe","title":"into_lazyframe","text":"<pre><code>into_lazyframe(\n    input_path,\n    chromosome_col,\n    position_col,\n    reference_col,\n    alternative_col,\n    info_cols,\n    /,\n    **scan_csv_args,\n)\n</code></pre> <p>Read a csv file and convert it in lazyframe.</p> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>pathlib.Path</code> <p>Path to csv.</p> required <code>chromosome_col</code> <code>str</code> <p>Name of the column that holds the chromosomes.</p> required <code>position_col</code> <code>str</code> <p>Name of the column that holds the positions.</p> required <code>reference_col</code> <code>str</code> <p>Name of the column that holds the reference sequence.</p> required <code>alternative_col</code> <code>str</code> <p>Name of the column that hold the alternative sequence.</p> required <code>scan_csv_args</code> <code>Unpack[ScanCsv]</code> <p>polars.scan_csv parameter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>A lazyframe that containt csv information</p> Source code in <code>src/variantplaner/io/csv.py</code> <pre><code>def into_lazyframe(\n    input_path: pathlib.Path,\n    chromosome_col: str,\n    position_col: str,\n    reference_col: str,\n    alternative_col: str,\n    info_cols: list[str],\n    /,\n    **scan_csv_args: Unpack[ScanCsv],\n) -&gt; polars.LazyFrame:\n\"\"\"Read a csv file and convert it in lazyframe.\n\n    Args:\n        input_path: Path to csv.\n        chromosome_col: Name of the column that holds the chromosomes.\n        position_col: Name of the column that holds the positions.\n        reference_col: Name of the column that holds the reference sequence.\n        alternative_col: Name of the column that hold the alternative sequence.\n        scan_csv_args: polars.scan_csv parameter.\n\n    Returns:\n        A lazyframe that containt csv information\n\n    \"\"\"\n    lf = polars.scan_csv(\n        input_path,\n        **scan_csv_args,\n    )\n\n    lf = lf.rename(\n        {\n            chromosome_col: \"chr\",\n            position_col: \"pos\",\n            reference_col: \"ref\",\n            alternative_col: \"alt\",\n        },\n    )\n\n    if info_cols:\n        lf = lf.select([\"chr\", \"pos\", \"ref\", \"alt\", *info_cols])\n\n    lf = normalization.chromosome2integer(lf)\n\n    lf = normalization.add_variant_id(lf)\n\n    return lf\n</code></pre>"},{"location":"reference/variantplaner/io/ped/","title":"ped","text":"<p>Function to manage input and output of ped file.</p>"},{"location":"reference/variantplaner/io/ped/#variantplaner.io.ped.from_lazyframe","title":"from_lazyframe","text":"<pre><code>from_lazyframe(lf, output_path)\n</code></pre> <p>Write pedigre polars.LazyFrame in ped format.</p> <p>Warning: This function perform LazyFrame.collect() before write csv, this can have a significant impact on memory usage</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>polars.LazyFrame</code> <p>LazyFrame contains pedigre information.</p> required <code>output_path</code> <code>pathlib.Path</code> <p>Path where write pedigre information.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/variantplaner/io/ped.py</code> <pre><code>def from_lazyframe(lf: polars.LazyFrame, output_path: pathlib.Path) -&gt; None:\n\"\"\"Write pedigre polars.LazyFrame in ped format.\n\n    Warning: This function perform LazyFrame.collect() before write csv, this can have a significant impact on memory usage\n\n    Args:\n        lf: LazyFrame contains pedigre information.\n        output_path: Path where write pedigre information.\n\n    Returns:\n        None\n    \"\"\"\n    lf.collect().write_csv(output_path, has_header=False, separator=\"\\t\")\n</code></pre>"},{"location":"reference/variantplaner/io/ped/#variantplaner.io.ped.into_lazyframe","title":"into_lazyframe","text":"<pre><code>into_lazyframe(input_path)\n</code></pre> <p>Read a pedigre file and convert it in polars.LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>pathlib.Path</code> <p>Path to pedigre file.</p> required <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>A lazyframe that containt ped information ('family_id', 'personal_id', 'father_id', 'mother_id', 'sex', 'affected')</p> Source code in <code>src/variantplaner/io/ped.py</code> <pre><code>def into_lazyframe(input_path: pathlib.Path) -&gt; polars.LazyFrame:\n\"\"\"Read a pedigre file and convert it in polars.LazyFrame.\n\n    Args:\n        input_path: Path to pedigre file.\n\n    Returns:\n        A lazyframe that containt ped information ('family_id', 'personal_id', 'father_id', 'mother_id', 'sex', 'affected')\n    \"\"\"\n    return polars.scan_csv(\n        input_path,\n        separator=\"\\t\",\n        has_header=False,\n        null_values=\"None\",\n        new_columns=[\"family_id\", \"personal_id\", \"father_id\", \"mother_id\", \"sex\", \"affected\"],\n        dtypes={\n            \"family_id\": polars.Utf8,\n            \"personal_id\": polars.Utf8,\n            \"father_id\": polars.Utf8,\n            \"mother_id\": polars.Utf8,\n            \"sex\": polars.Utf8,\n            \"affected\": polars.Boolean,\n        },\n    )\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/","title":"vcf","text":"<p>Function to manage input and output of vcf file.</p>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.IntoLazyFrameExtension","title":"IntoLazyFrameExtension","text":"<p>         Bases: <code>enum.Enum</code></p> <p>Enumration use to control behavior of IntoLazyFrame.</p>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.add_info_column","title":"add_info_column","text":"<pre><code>add_info_column(lf, vcfinfo2parquet_name)\n</code></pre> <p>Construct an INFO column from multiple columns of lf.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>polars.LazyFrame</code> <p>A dataframe.</p> required <code>vcfinfo2parquet_name</code> <code>list[tuple[str, str]]</code> <p>List of vcf column name and lf column name.</p> required <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>LazyFrame with INFO column and remove lf column use.</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def add_info_column(lf: polars.LazyFrame, vcfinfo2parquet_name: list[tuple[str, str]]) -&gt; polars.LazyFrame:\n\"\"\"Construct an INFO column from multiple columns of lf.\n\n    Args:\n        lf: A dataframe.\n        vcfinfo2parquet_name: List of vcf column name and lf column name.\n\n    Returns:\n        LazyFrame with INFO column and remove lf column use.\n    \"\"\"\n    lf = lf.with_columns(\n        [\n            polars.col(name).list.join(\",\").fill_null(\".\").alias(name)\n            for name, dtype in zip(lf.columns, lf.dtypes)\n            if isinstance(dtype, polars.List)\n        ],\n    )\n\n    lf = lf.with_columns(\n        [\n            polars.col(name).cast(str).fill_null(\".\").alias(name)\n            for name, dtype in zip(lf.columns, lf.dtypes)\n            if not isinstance(dtype, polars.List)\n        ],\n    )\n\n    lf = lf.with_columns(\n        [\n            polars.concat_str(\n                [\n                    polars.concat_str(\n                        [\n                            polars.lit(vcf_name),\n                            polars.lit(\"=\"),\n                            polars.col(parquet_name),\n                        ],\n                    )\n                    for vcf_name, parquet_name in vcfinfo2parquet_name\n                ],\n                separator=\";\",\n            ).alias(\"INFO\"),\n        ],\n    )\n\n    lf = lf.drop([p for (v, p) in vcfinfo2parquet_name])\n\n    return lf\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.build_rename_column","title":"build_rename_column","text":"<pre><code>build_rename_column(\n    chromosome,\n    pos,\n    identifier,\n    ref,\n    alt,\n    qual=\".\",\n    filter_col=\".\",\n    info=None,\n    format_string=None,\n    sample=None,\n)\n</code></pre> <p>An helper function to generate rename column dict for io.vcf.from_lazyframe function parameter.</p> <p>Returns:</p> Type Description <code>RenameCol</code> <p>A rename column dictionary.</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def build_rename_column(\n    chromosome: str,\n    pos: str,\n    identifier: str,\n    ref: str,\n    alt: str,\n    qual: str | None = \".\",\n    filter_col: str | None = \".\",\n    info: list[tuple[str, str]] | None = None,\n    format_string: str | None = None,\n    sample: dict[str, dict[str, str]] | None = None,\n) -&gt; RenameCol:\n\"\"\"An helper function to generate rename column dict for io.vcf.from_lazyframe function parameter.\n\n    Returns:\n        A rename column dictionary.\n    \"\"\"\n    return {\n        \"#CHROM\": chromosome,\n        \"POS\": pos,\n        \"ID\": identifier,\n        \"REF\": ref,\n        \"ALT\": alt,\n        \"QUAL\": \".\" if qual is None else qual,\n        \"FILTER\": \".\" if filter_col is None else filter_col,\n        \"INFO\": [] if info is None else info,\n        \"FORMAT\": \"\" if format_string is None else format_string,\n        \"sample\": {} if sample is None else sample,\n    }\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.extract_header","title":"extract_header","text":"<pre><code>extract_header(input_path)\n</code></pre> <p>Extract all header information of vcf file.</p> <p>Line between start of file and first line start with '#CHROM' or not start with '#'</p> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>pathlib.Path</code> <p>Path to vcf file.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of header string.</p> <p>Raises:</p> Type Description <code>NotAVCFError</code> <p>If a line not starts with '#'</p> <code>NotAVCFError</code> <p>If all line not start by '#CHROM'</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def extract_header(input_path: pathlib.Path) -&gt; list[str]:\n\"\"\"Extract all header information of vcf file.\n\n    Line between start of file and first line start with '#CHROM' or not start with '#'\n\n    Args:\n        input_path: Path to vcf file.\n\n    Returns:\n        List of header string.\n\n    Raises:\n        NotAVCFError: If a line not starts with '#'\n        NotAVCFError: If all line not start by '#CHROM'\n    \"\"\"\n    headers = []\n    with open(input_path) as fh:\n        for line in (full_line.strip() for full_line in fh):\n            if not line.startswith(\"#\"):\n                raise NotAVCFError(input_path)\n\n            if line.startswith(\"#CHROM\"):\n                headers.append(line)\n                return headers\n\n            headers.append(line)\n\n    raise NotAVCFError(input_path)\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.format2expr","title":"format2expr","text":"<pre><code>format2expr(header, input_path, select_format=None)\n</code></pre> <p>Read vcf header to generate a list of polars.Expr to extract genotypes informations.</p> <p>Warning: Float values can't be converted for the moment they are stored as String to keep information</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>list[str]</code> <p>Line of vcf header.</p> required <code>input_path</code> <code>pathlib.Path</code> <p>Path to vcf file.</p> required <code>select_format</code> <code>set[str] | None</code> <p>List of target format field.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Callable[[polars.Expr, str], polars.Expr]]</code> <p>A dict to link format id to pipeable function with Polars.Expr</p> <p>Raises:</p> Type Description <code>NotAVCFError</code> <p>If all line not start by '#CHR'</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def format2expr(\n    header: list[str],\n    input_path: pathlib.Path,\n    select_format: set[str] | None = None,\n) -&gt; dict[str, Callable[[polars.Expr, str], polars.Expr]]:\n\"\"\"Read vcf header to generate a list of polars.Expr to extract genotypes informations.\n\n    **Warning**: Float values can't be converted for the moment they are stored as String to keep information\n\n    Args:\n        header: Line of vcf header.\n        input_path: Path to vcf file.\n        select_format: List of target format field.\n\n    Returns:\n        A dict to link format id to pipeable function with Polars.Expr\n\n    Raises:\n        NotAVCFError: If all line not start by '#CHR'\n    \"\"\"\n    format_re = re.compile(\n        \"ID=(?P&lt;id&gt;[A-Za-z_][0-9A-Za-z_.]*),Number=(?P&lt;number&gt;[ARG0-9\\\\.]+),Type=(?P&lt;type&gt;Integer|Float|String|Character)\",\n    )\n\n    expressions: dict[str, Callable[[polars.Expr, str], polars.Expr]] = {}\n\n    for line in header:\n        if line.startswith(\"#CHROM\"):\n            return expressions\n\n        if not line.startswith(\"##FORMAT\"):\n            continue\n\n        if (search := format_re.search(line)) and (not select_format or search[\"id\"] in select_format):\n            name = search[\"id\"]\n            number = search[\"number\"]\n            format_type = search[\"type\"]\n\n            if name == \"GT\":\n                expressions[\"GT\"] = __format_gt\n                continue\n\n            if number == \"1\":\n                if format_type == \"Integer\":\n                    expressions[name] = __format_one_int\n                elif format_type == \"Float\":  # noqa: SIM114 Float isn't already support but in future\n                    expressions[name] = __format_one_str\n                elif format_type == \"String\" or format_type == \"Character\":\n                    expressions[name] = __format_one_str\n                else:\n                    pass  # Not reachable\n\n            else:\n                if format_type == \"Integer\":  # noqa: PLR5501 All other number are consider as list\n                    expressions[name] = __format_list_int\n                elif format_type == \"Float\":  # noqa: SIM114 Float isn't already support but in future\n                    expressions[name] = __format_list_str\n                elif format_type == \"String\" or format_type == \"Character\":\n                    expressions[name] = __format_list_str\n                else:\n                    pass  # Not reachable\n\n    raise NotAVCFError(input_path)\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.from_lazyframe","title":"from_lazyframe","text":"<pre><code>from_lazyframe(lf, output_path, renaming=DEFAULT_RENAME)\n</code></pre> <p>Write polars.LazyFrame in vcf format.</p> Chromosome name mapping table <ul> <li>23: X</li> <li>24: Y</li> <li>25: MT</li> </ul> <p>All other chromosome number isn't change.</p> <p>Warning: This function perform LazyFrame.collect() before write csv, this can have a significant impact on memory usage.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>polars.LazyFrame</code> <p>LazyFrame contains information.</p> required <code>output_path</code> <code>pathlib.Path</code> <p>Path to where vcf to write.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def from_lazyframe(\n    lf: polars.LazyFrame,\n    output_path: pathlib.Path,\n    renaming: RenameCol = DEFAULT_RENAME,\n) -&gt; None:\n\"\"\"Write polars.LazyFrame in vcf format.\n\n    Chromosome name mapping table:\n      - 23: X\n      - 24: Y\n      - 25: MT\n\n    All other chromosome number isn't change.\n\n    Warning: This function perform LazyFrame.collect() before write csv, this can have a significant impact on memory usage.\n\n    Args:\n        lf: LazyFrame contains information.\n        output_path: Path to where vcf to write.\n\n    Returns:\n        None\n    \"\"\"\n    select_column: list[str] = []\n\n    lf = lf.with_columns(\n        [\n            polars.col(renaming[\"#CHROM\"])\n            .cast(polars.Utf8)\n            .str.replace(\"23\", \"X\")\n            .str.replace(\"24\", \"Y\")\n            .str.replace(\"25\", \"MT\")\n            .alias(\"#CHROM\"),\n            polars.col(renaming[\"POS\"]).alias(\"POS\"),\n            polars.col(renaming[\"ID\"]).alias(\"ID\"),\n            polars.col(renaming[\"REF\"]).alias(\"REF\"),\n            polars.col(renaming[\"ALT\"]).alias(\"ALT\"),\n        ],\n    )\n\n    select_column.extend([\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\"])\n\n    header = __generate_header(lf, renaming[\"INFO\"], list(renaming[\"sample\"].keys()), renaming[\"FORMAT\"])\n\n    if renaming[\"QUAL\"] != \".\":\n        lf = lf.with_columns([polars.col(renaming[\"QUAL\"]).alias(\"QUAL\")])\n    else:\n        lf = lf.with_columns([polars.lit(\".\").alias(\"QUAL\")])\n\n    select_column.append(\"QUAL\")\n\n    if renaming[\"FILTER\"] != \".\":\n        lf = lf.with_columns([polars.col(renaming[\"FILTER\"]).alias(\"FILTER\")])\n    else:\n        lf = lf.with_columns([polars.lit(\".\").alias(\"FILTER\")])\n\n    select_column.append(\"FILTER\")\n\n    lf = add_info_column(lf, renaming[\"INFO\"]) if renaming[\"INFO\"] else lf.with_columns(polars.lit(\".\").alias(\"INFO\"))\n\n    select_column.append(\"INFO\")\n\n    if renaming[\"FORMAT\"]:\n        lf = lf.with_columns(polars.lit(renaming[\"FORMAT\"]).alias(\"FORMAT\"))\n        select_column.append(\"FORMAT\")\n\n    if renaming[\"FORMAT\"] and renaming[\"sample\"]:\n        for sample_name in renaming[\"sample\"]:\n            lf = lf.with_columns(\n                [\n                    __lazy2format(sample_name, renaming[\"FORMAT\"], dict(zip(lf.columns, lf.dtypes))).alias(sample_name),\n                ],\n            )\n            select_column.append(sample_name)\n\n    lf = lf.select([polars.col(col) for col in select_column])\n\n    with open(output_path, \"wb\") as fh:\n        fh.write(header.encode())\n        fh.write(lf.collect().write_csv(separator=\"\\t\").encode())\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.info2expr","title":"info2expr","text":"<pre><code>info2expr(header, input_path, select_info=None)\n</code></pre> <p>Read vcf header to generate a list of polars.Expr to extract variants informations.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>list[str]</code> <p>Line of vcf header</p> required <code>input_path</code> <code>pathlib.Path</code> <p>Path to vcf file.</p> required <code>select_info</code> <code>set[str] | None</code> <p>List of target info field</p> <code>None</code> <p>Returns:</p> Type Description <code>list[polars.Expr]</code> <p>List of polars expr to parse info columns.</p> <p>Raises:</p> Type Description <code>NotAVCFError</code> <p>If all line not start by '#CHR'</p> <code>NotSupportType</code> <p>If header line indicate a not support type</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def info2expr(header: list[str], input_path: pathlib.Path, select_info: set[str] | None = None) -&gt; list[polars.Expr]:\n\"\"\"Read vcf header to generate a list of polars.Expr to extract variants informations.\n\n    Args:\n        header: Line of vcf header\n        input_path: Path to vcf file.\n        select_info: List of target info field\n\n    Returns:\n        List of polars expr to parse info columns.\n\n    Raises:\n        NotAVCFError: If all line not start by '#CHR'\n        NotSupportType: If header line indicate a not support type\n    \"\"\"\n    info_re = re.compile(\n        r\"ID=(?P&lt;id&gt;([A-Za-z_][0-9A-Za-z_.]*|1000G)),Number=(?P&lt;number&gt;[ARG0-9\\.]+),Type=(?P&lt;type&gt;Integer|Float|String|Character)\",\n    )\n\n    expressions: list[polars.Expr] = []\n\n    for line in header:\n        if line.startswith(\"#CHROM\"):\n            return expressions\n\n        if not line.startswith(\"##INFO\"):\n            continue\n\n        if (search := info_re.search(line)) and (not select_info or search[\"id\"] in select_info):\n            regex = rf\"{search['id']}=([^;]+);?\"\n\n            local_expr = polars.col(\"info\").str.extract(regex, 1)\n\n            if search[\"number\"] == \"1\":\n                if search[\"type\"] == \"Integer\":\n                    local_expr = local_expr.cast(polars.Int64)\n                elif search[\"type\"] == \"Float\":\n                    local_expr = local_expr.cast(polars.Float64)\n                elif search[\"type\"] == \"String\" or search[\"type\"] == \"Character\":\n                    pass  # Not do anything on string or character\n                else:\n                    pass  # Not reachable\n\n            else:\n                local_expr = local_expr.str.split(\",\")\n                if search[\"type\"] == \"Integer\":\n                    local_expr = local_expr.cast(polars.List(polars.Int64))\n                elif search[\"type\"] == \"Float\":\n                    local_expr = local_expr.cast(polars.List(polars.Float64))\n                elif search[\"type\"] == \"String\" or search[\"type\"] == \"Character\":\n                    pass  # Not do anything on string or character\n                else:\n                    pass  # Not reachable\n\n            expressions.append(local_expr.alias(search[\"id\"]))\n\n    raise NotAVCFError(input_path)\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.into_lazyframe","title":"into_lazyframe","text":"<pre><code>into_lazyframe(\n    input_path, extension=IntoLazyFrameExtension.NOTHING\n)\n</code></pre> <p>Read a vcf file and convert it in lazyframe.</p> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>pathlib.Path</code> <p>Path to vcf file.</p> required <p>Returns:</p> Type Description <code>polars.LazyFrame</code> <p>A lazyframe that containt vcf information ('chr', 'pos', 'vid', 'ref', 'alt', 'qual', 'filter', 'info', ['format'], ['genotypes',\u2026], 'id').</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def into_lazyframe(\n    input_path: pathlib.Path,\n    extension: IntoLazyFrameExtension = IntoLazyFrameExtension.NOTHING,\n) -&gt; polars.LazyFrame:\n\"\"\"Read a vcf file and convert it in lazyframe.\n\n    Args:\n        input_path: Path to vcf file.\n\n    Returns:\n        A lazyframe that containt vcf information ('chr', 'pos', 'vid', 'ref', 'alt', 'qual', 'filter', 'info', ['format'], ['genotypes',\u2026], 'id').\n    \"\"\"\n    header = extract_header(input_path)\n\n    col_name = {f\"column_{i}\": name for (i, name) in enumerate(__column_name(header, input_path), start=1)}\n\n    lf = polars.scan_csv(\n        input_path,\n        separator=\"\\t\",\n        comment_char=\"#\",\n        has_header=False,\n        dtypes={\"column_1\": polars.Utf8},\n        ignore_errors=True,\n    )\n\n    lf = lf.rename(col_name)\n\n    if extension == IntoLazyFrameExtension.MANAGE_SV:\n        lf = lf.with_columns(info2expr(header, input_path, {\"SVTYPE\", \"SVLEN\"}))\n\n    lf = normalization.chromosome2integer(lf)\n\n    lf = normalization.add_variant_id(lf)\n\n    if extension == IntoLazyFrameExtension.MANAGE_SV:\n        drop_column = {\"SVTYPE\", \"SVLEN\"}\n        lf = lf.collect().select([col for col in lf.columns if col not in drop_column]).lazy()\n\n    return lf\n</code></pre>"},{"location":"reference/variantplaner/io/vcf/#variantplaner.io.vcf.sample_index","title":"sample_index","text":"<pre><code>sample_index(header, input_path)\n</code></pre> <p>Read vcf header to generate an association map between sample name and index.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>list[str]</code> <p>Header string.</p> required <p>Returns:</p> Type Description <code>dict[str, int] | None</code> <p>Map that associate a sample name to is sample index.</p> <p>Raises:</p> Type Description <code>NotAVCFError</code> <p>If all line not start by '#CHR'</p> Source code in <code>src/variantplaner/io/vcf.py</code> <pre><code>def sample_index(header: list[str], input_path: pathlib.Path) -&gt; dict[str, int] | None:\n\"\"\"Read vcf header to generate an association map between sample name and index.\n\n    Args:\n        header: Header string.\n\n    Returns:\n        Map that associate a sample name to is sample index.\n\n    Raises:\n        NotAVCFError: If all line not start by '#CHR'\n    \"\"\"\n    for line in reversed(header):\n        if line.startswith(\"#CHR\"):\n            split_line = line.strip().split(\"\\t\")\n            if len(split_line) &lt;= MINIMAL_COL_NUMBER:\n                return None\n\n            return {sample: i for (i, sample) in enumerate(split_line[SAMPLE_COL_BEGIN:])}\n\n    raise NotAVCFError(input_path)\n</code></pre>"},{"location":"reference/variantplaner/struct/","title":"struct","text":"<p>Module manage data struct.</p>"},{"location":"reference/variantplaner/struct/genotypes/","title":"genotypes","text":"<p>Function relate to partition of genotype.</p>"},{"location":"reference/variantplaner/struct/genotypes/#variantplaner.struct.genotypes.hive","title":"hive","text":"<pre><code>hive(paths, output_prefix, threads=1)\n</code></pre> <p>Read all genotypes parquet file and use information to generate a hive like struct with genotype informations.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>list[pathlib.Path]</code> <p>List of file you want reorganise</p> required <code>output_prefix</code> <code>pathlib.Path</code> <p>prefix of hive</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/variantplaner/struct/genotypes.py</code> <pre><code>def hive(paths: list[pathlib.Path], output_prefix: pathlib.Path, threads: int = 1) -&gt; None:\n\"\"\"Read all genotypes parquet file and use information to generate a hive like struct with genotype informations.\n\n    Args:\n        paths: List of file you want reorganise\n        output_prefix: prefix of hive\n\n    Returns:\n        None\n    \"\"\"\n    threads = min(threads, len(paths))\n\n    with multiprocessing.get_context(\"spawn\").Pool(threads) as pool:\n        pool.starmap(__hive_worker, [(path, output_prefix) for path in paths])\n</code></pre>"},{"location":"reference/variantplaner/struct/variants/","title":"variants","text":"<p>Function relate to merge of vcf.</p>"},{"location":"reference/variantplaner/struct/variants/#variantplaner.struct.variants.merge","title":"merge","text":"<pre><code>merge(paths, output, memory_limit=10000000000)\n</code></pre> <p>Perform merge of multiple parquet variants file in one file.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>list[pathlib.Path]</code> <p>List of file you want chunked.</p> required <code>output</code> <code>pathlib.Path</code> <p>Path where variants is write.</p> required <code>memory_limit</code> <code>int</code> <p>Size of each chunk in bytes.</p> <code>10000000000</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/variantplaner/struct/variants.py</code> <pre><code>def merge(paths: list[pathlib.Path], output: pathlib.Path, memory_limit: int = 10_000_000_000) -&gt; None:\n\"\"\"Perform merge of multiple parquet variants file in one file.\n\n    Args:\n        paths: List of file you want chunked.\n        output: Path where variants is write.\n        memory_limit: Size of each chunk in bytes.\n\n    Returns:\n        None\n    \"\"\"\n    inputs = paths\n    temp_directory = tempfile.TemporaryDirectory()\n    temp_prefix = pathlib.Path(temp_directory.name)\n    logger.debug(f\"{temp_prefix=}\")\n\n    while len(inputs) != 1:\n        new_inputs = []\n\n        for input_chunk in __chunk_by_memory(inputs, bytes_limit=memory_limit):\n            logger.debug(f\"{len(input_chunk)=}\")\n            if len(input_chunk) &gt; 1:\n                # general case\n                temp_output = temp_prefix / __random_string()\n\n                new_inputs.append(temp_output)\n                __concat_uniq(input_chunk, temp_output)\n\n            elif len(input_chunk) == 1:\n                # if chunk containt only one file it's last file of inputs\n                # we add it to new_inputs list\n                new_inputs.append(input_chunk[0])\n\n            logger.debug(f\"{new_inputs=}\")\n            inputs = new_inputs\n\n    # When loop finish we have one file in inputs with all merge\n    # We just have to rename it\n    shutil.move(inputs[0], output)\n\n    # Call cleanup to remove all tempfile generate durring merging\n    temp_directory.cleanup()\n</code></pre>"},{"location":"coverage/","title":"Coverage report","text":""}]}